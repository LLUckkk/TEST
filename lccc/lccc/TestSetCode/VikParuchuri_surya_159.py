import json
import traceback
import threading
import queue
import time
from contextlib import contextmanager
import requests

import torch


#############change###########
def to(self, device_dtype: torch.device | str | None = None):
    if self.model:
        self.model.to(device_dtype)
    else:
        raise ValueError("Model not loaded")


#############change###########


@contextmanager
def request_context():
    """ç¡®ä¿requestsä¼šè¯è¢«æ­£ç¡®å…³é—­çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    session = requests.Session()
    try:
        yield session
    finally:
        session.close()


def safe_execute_testcase(testcase_func, timeout):
    """å®Œå…¨è§£å†³çº¿ç¨‹æ®‹ç•™é—®é¢˜çš„æ‰§è¡Œå™¨"""
    result_queue = queue.Queue()
    event = threading.Event()  # çº¿ç¨‹åè°ƒäº‹ä»¶

    def worker():
        try:
            with request_context() as session:
                # å°†sessionä¼ é€’ç»™æµ‹è¯•å‡½æ•°ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if 'session' in testcase_func.__code__.co_varnames:
                    result = testcase_func(session=session)
                else:
                    result = testcase_func()

                if not event.is_set():
                    result_queue.put(('success', result))
        except Exception as e:
            if not event.is_set():
                result_queue.put(('error', e))
        finally:
            event.set()  # æ ‡è®°çº¿ç¨‹å·²å®Œæˆ

    t = threading.Thread(target=worker)
    t.daemon = True  # å¿…é¡»è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹

    start_time = time.time()
    t.start()

    # ç­‰å¾…çº¿ç¨‹å®Œæˆæˆ–è¶…æ—¶
    while time.time() - start_time < timeout:
        if event.is_set() or not result_queue.empty():
            break
        time.sleep(0.1)

    event.set()  # é€šçŸ¥çº¿ç¨‹ç»ˆæ­¢

    if not result_queue.empty():
        status, data = result_queue.get_nowait()
        return {
            'success': status == 'success',
            'result': data if status == 'success' else None,
            'error': None if status == 'success' else str(data),
            'traceback': traceback.format_exc() if status == 'error' else None
        }

    return {
        'success': False,
        'error': f'Timeout after {timeout} seconds',
        'traceback': 'Test execution timed out'
    }


# å®šä¹‰æµ‹è¯•ç”¨ä¾‹1
def testcase_1():
    class Dummy:
        def __init__(self):
            self.model = torch.nn.Linear(10, 10)  # ğŸ‘ˆ åŠ äº†ä¸€ä¸ªå¯æ‰§è¡Œçš„æ¨¡å‹

    self = Dummy()
    device_dtype = torch.device('cuda')
    to(self, device_dtype)
    # è·å–æ¨¡å‹å®é™…æ‰€åœ¨è®¾å¤‡
    actual_device = next(self.model.parameters()).device
    # åˆ¤æ–­å®é™…è®¾å¤‡æ˜¯å¦ä¸é¢„æœŸè®¾å¤‡åŒ¹é…
    expected_device = torch.device(device_dtype)
    return actual_device == expected_device


# å®šä¹‰æµ‹è¯•ç”¨ä¾‹2
def testcase_2():
    class Dummy:
        def __init__(self):
            self.model = torch.nn.Linear(10, 10)  # ğŸ‘ˆ åŠ äº†ä¸€ä¸ªå¯æ‰§è¡Œçš„æ¨¡å‹

    self = Dummy()
    device_dtype = 'cpu'
    to(self, device_dtype)
    # è·å–æ¨¡å‹å®é™…æ‰€åœ¨è®¾å¤‡
    actual_device = next(self.model.parameters()).device
    # åˆ¤æ–­å®é™…è®¾å¤‡æ˜¯å¦ä¸é¢„æœŸè®¾å¤‡åŒ¹é…
    expected_device = torch.device(device_dtype)
    return actual_device == expected_device


# å®šä¹‰æµ‹è¯•ç”¨ä¾‹3
def testcase_3():
    class Dummy:
        def __init__(self):
            self.model = torch.nn.Linear(10, 10)  # ğŸ‘ˆ åŠ äº†ä¸€ä¸ªå¯æ‰§è¡Œçš„æ¨¡å‹

    self = Dummy()
    device_dtype = torch.device('cuda:0')
    to(self, device_dtype)
    # è·å–æ¨¡å‹å®é™…æ‰€åœ¨è®¾å¤‡
    actual_device = next(self.model.parameters()).device
    # åˆ¤æ–­å®é™…è®¾å¤‡æ˜¯å¦ä¸é¢„æœŸè®¾å¤‡åŒ¹é…
    expected_device = torch.device(device_dtype)
    return actual_device == expected_device


# å®šä¹‰æµ‹è¯•ç”¨ä¾‹4
def testcase_4():
    class Dummy:
        def __init__(self):
            self.model = torch.nn.Linear(10, 10)  # ğŸ‘ˆ åŠ äº†ä¸€ä¸ªå¯æ‰§è¡Œçš„æ¨¡å‹

    self = Dummy()
    device_dtype = 'cuda'

    to(self, device_dtype)
    # è·å–æ¨¡å‹å®é™…æ‰€åœ¨è®¾å¤‡
    actual_device = next(self.model.parameters()).device
    # åˆ¤æ–­å®é™…è®¾å¤‡æ˜¯å¦ä¸é¢„æœŸè®¾å¤‡åŒ¹é…
    expected_device = torch.device(device_dtype)
    return actual_device == expected_device


# å®šä¹‰æµ‹è¯•ç”¨ä¾‹5
def testcase_5():
    class Dummy:
        def __init__(self):
            self.model = torch.nn.Linear(10, 10)  # ğŸ‘ˆ åŠ äº†ä¸€ä¸ªå¯æ‰§è¡Œçš„æ¨¡å‹

    self = Dummy()
    device_dtype = None

    to(self, device_dtype)
    # è·å–æ¨¡å‹å®é™…æ‰€åœ¨è®¾å¤‡
    actual_device = next(self.model.parameters()).device
    # åˆ¤æ–­å®é™…è®¾å¤‡æ˜¯å¦ä¸é¢„æœŸè®¾å¤‡åŒ¹é…
    expected_device = torch.device(device_dtype)
    return actual_device == expected_device


def main():
    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
    test_results = {
        "ans1": safe_execute_testcase(testcase_1, timeout=5),
        "ans2": safe_execute_testcase(testcase_2, timeout=5),
        "ans3": safe_execute_testcase(testcase_3, timeout=5),
        "ans4": safe_execute_testcase(testcase_4, timeout=5),
        "ans5": safe_execute_testcase(testcase_5, timeout=5)
    }

    output = {
        "ans1": test_results["ans1"]["result"] if test_results["ans1"]["success"] else None,
        "ans2": test_results["ans2"]["result"] if test_results["ans2"]["success"] else None,
        "ans3": test_results["ans3"]["result"] if test_results["ans3"]["success"] else None,
        "ans4": test_results["ans4"]["result"] if test_results["ans4"]["success"] else None,
        "ans5": test_results["ans5"]["result"] if test_results["ans5"]["success"] else None
    }

    print(json.dumps(output, indent=2))


if __name__ == '__main__':
    main()
