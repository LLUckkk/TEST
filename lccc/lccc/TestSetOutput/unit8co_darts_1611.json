{
  "input_header": "def helper_create_model( self, use_encoders=True, add_relative_idx=True, full_attention=False ):",
  "input_docstring": null,
  "output_code": "    def helper_create_model(\n        self, use_encoders=True, add_relative_idx=True, full_attention=False\n    ):\n        add_encoders = (\n            {\"cyclic\": {\"past\": [\"month\"], \"future\": [\"month\"]}}\n            if use_encoders\n            else None\n        )\n        return TFTModel(\n            input_chunk_length=5,\n            output_chunk_length=2,\n            n_epochs=1,\n            add_encoders=add_encoders,\n            add_relative_index=add_relative_idx,\n            full_attention=full_attention,\n            random_state=42,\n            **tfm_kwargs,\n        )",
  "input_contexts": [
    {
      "id": "unit8co_darts_1611_3",
      "input_code": "    def test_variable_selection_explanation(self):\n        \n        model = self.helper_create_model(use_encoders=True, add_relative_idx=True)\n        series, pc, fc = self.helper_get_input(series_option=\"multivariate\")\n        model.fit(series, past_covariates=pc, future_covariates=fc)\n        explainer = TFTExplainer(model)\n        results = explainer.explain()\n\n        imps = results.get_feature_importances()\n        enc_imp = results.get_encoder_importance()\n        dec_imp = results.get_decoder_importance()\n        stc_imp = results.get_static_covariates_importance()\n        imps_direct = [enc_imp, dec_imp, stc_imp]\n\n        imp_names = [\n            \"encoder_importance\",\n            \"decoder_importance\",\n            \"static_covariates_importance\",\n        ]\n        assert list(imps.keys()) == imp_names\n        for imp, imp_name in zip(imps_direct, imp_names):\n            assert imps[imp_name].equals(imp)\n\n        enc_expected = pd.DataFrame(\n            {\n                \"linear_target\": 1.7,\n                \"sine_target\": 3.1,\n                \"add_relative_index_futcov\": 3.6,\n                \"constant_pastcov\": 3.9,\n                \"darts_enc_fc_cyc_month_sin_futcov\": 5.0,\n                \"darts_enc_pc_cyc_month_sin_pastcov\": 10.1,\n                \"darts_enc_pc_cyc_month_cos_pastcov\": 19.9,\n                \"constant_futcov\": 21.8,\n                \"darts_enc_fc_cyc_month_cos_futcov\": 31.0,\n            },\n            index=[0],\n        )\n        assert ((enc_imp.round(decimals=1) - enc_expected).abs() <= 3).all().all()\n\n        dec_expected = pd.DataFrame(\n            {\n                \"darts_enc_fc_cyc_month_sin_futcov\": 5.3,\n                \"darts_enc_fc_cyc_month_cos_futcov\": 7.4,\n                \"constant_futcov\": 24.5,\n                \"add_relative_index_futcov\": 62.9,\n            },\n            index=[0],\n        )\n        assert ((dec_imp.round(decimals=1) - dec_expected).abs() <= 0.6).all().all()\n\n        stc_expected = pd.DataFrame(\n            {\"num_statcov\": 11.9, \"cat_statcov\": 88.1}, index=[0]\n        )\n        assert ((stc_imp.round(decimals=1) - stc_expected).abs() <= 0.1).all().all()\n\n        with patch(\"matplotlib.pyplot.show\") as _:\n            _ = explainer.plot_variable_selection(results)\n"
    },
    {
      "id": "unit8co_darts_1611_4",
      "input_code": "    def test_attention_explanation(self):\n        \n        att_exp_past_att = np.array([\n            [1.0, 0.8],\n            [0.8, 0.7],\n            [0.6, 0.4],\n            [0.7, 0.3],\n            [0.9, 0.4],\n            [0.0, 1.3],\n            [0.0, 0.0],\n        ])\n        att_exp_full_att = np.array([\n            [0.8, 0.8],\n            [0.7, 0.6],\n            [0.4, 0.4],\n            [0.3, 0.3],\n            [0.3, 0.3],\n            [0.7, 0.8],\n            [0.8, 0.8],\n        ])\n        for full_attention, att_exp in zip(\n            [False, True], [att_exp_past_att, att_exp_full_att]\n        ):\n            model = self.helper_create_model(\n                use_encoders=True,\n                add_relative_idx=True,\n                full_attention=full_attention,\n            )\n            series, pc, fc = self.helper_get_input(series_option=\"multivariate\")\n            model.fit(series, past_covariates=pc, future_covariates=fc)\n            explainer = TFTExplainer(model)\n            results = explainer.explain()\n\n            att = results.get_attention()\n            assert np.all(np.abs(np.round(att.values(), decimals=1) - att_exp) <= 0.2)\n            assert att.columns.tolist() == [\"horizon 1\", \"horizon 2\"]\n            with patch(\"matplotlib.pyplot.show\") as _:\n                _ = explainer.plot_attention(\n                    results, plot_type=\"all\", show_index_as=\"relative\"\n                )\n                plt.close()\n            with patch(\"matplotlib.pyplot.show\") as _:\n                _ = explainer.plot_attention(\n                    results, plot_type=\"all\", show_index_as=\"time\"\n                )\n                plt.close()\n            with patch(\"matplotlib.pyplot.show\") as _:\n                _ = explainer.plot_attention(\n                    results, plot_type=\"time\", show_index_as=\"relative\"\n                )\n                plt.close()\n            with patch(\"matplotlib.pyplot.show\") as _:\n                _ = explainer.plot_attention(\n                    results, plot_type=\"time\", show_index_as=\"time\"\n                )\n                plt.close()\n            with patch(\"matplotlib.pyplot.show\") as _:\n                _ = explainer.plot_attention(\n                    results, plot_type=\"heatmap\", show_index_as=\"relative\"\n                )\n                plt.close()\n            with patch(\"matplotlib.pyplot.show\") as _:\n                _ = explainer.plot_attention(\n                    results, plot_type=\"heatmap\", show_index_as=\"time\"\n                )\n                plt.close()\n"
    },
    {
      "id": "unit8co_darts_1611_2",
      "input_code": "    def test_explainer_multiple_multivariate_series(self, test_case):\n        \n        series_option, cov_option, add_relative_idx, use_encoders = test_case\n        series, pc, fc = self.helper_get_input(series_option)\n        cov_test_case = dict()\n        use_pc, use_fc = False, False\n        if \"past_covariates\" in cov_option:\n            cov_test_case[\"past_covariates\"] = pc\n            use_pc = True\n        if \"future_covariates\" in cov_option:\n            cov_test_case[\"future_covariates\"] = fc\n            use_fc = True\n\n        n_target_expected = series[0].n_components\n        n_pc_expected = 1 if \"past_covariates\" in cov_test_case else 0\n        n_fc_expected = 1 if \"future_covariates\" in cov_test_case else 0\n        n_sc_expected = 2\n        n_enc_expected = (\n            n_pc_expected\n            + n_fc_expected\n            + n_target_expected\n            + (4 if use_encoders else 0)\n            + (1 if add_relative_idx else 0)\n        )\n        n_dec_expected = (\n            n_fc_expected + (2 if use_encoders else 0) + (1 if add_relative_idx else 0)\n        )\n        model = self.helper_create_model(\n            use_encoders=use_encoders, add_relative_idx=add_relative_idx\n        )\n        if (\n            not add_relative_idx\n            and \"future_covariates\" not in cov_test_case\n            and not use_encoders\n        ):\n            with pytest.raises(ValueError):\n                model.fit(series=series, **cov_test_case)\n            return\n\n        model.fit(series=series, **cov_test_case)\n        with pytest.raises(ValueError):\n            explainer = TFTExplainer(model)\n        explainer = TFTExplainer(\n            model,\n            background_series=series,\n            background_past_covariates=pc if use_pc else None,\n            background_future_covariates=fc if use_fc else None,\n        )\n        assert hasattr(explainer, \"model\")\n        assert explainer.background_series, series\n        if use_pc:\n            assert explainer.background_past_covariates == pc\n            assert explainer.background_past_covariates[0].n_components == n_pc_expected\n        else:\n            assert explainer.background_past_covariates is None\n        if use_fc:\n            assert explainer.background_future_covariates == fc\n            assert (\n                explainer.background_future_covariates[0].n_components == n_fc_expected\n            )\n        else:\n            assert explainer.background_future_covariates is None\n        result = explainer.explain()\n        assert isinstance(result, TFTExplainabilityResult)\n\n        enc_imp = result.get_encoder_importance()\n        dec_imp = result.get_decoder_importance()\n        stc_imp = result.get_static_covariates_importance()\n        imps = [enc_imp, dec_imp, stc_imp]\n        assert all([isinstance(imp, list) for imp in imps])\n        assert all([len(imp) == len(series) for imp in imps])\n        assert all([isinstance(imp_, pd.DataFrame) for imp in imps for imp_ in imp])\n        assert all([\n            imp_.squeeze().sum() == pytest.approx(100.0, abs=0.21)\n            for imp in imps\n            for imp_ in imp\n        ])\n        assert all([\n            len(imp_.columns) == n\n            for imp, n in zip(imps, [n_enc_expected, n_dec_expected, n_sc_expected])\n            for imp_ in imp\n        ])\n\n        attention = result.get_attention()\n        assert isinstance(attention, list)\n        assert len(attention) == len(series)\n        assert all([isinstance(att, TimeSeries) for att in attention])\n        icl, ocl = 5, 2\n        freq = series[0].freq\n        assert all([len(att) == icl + ocl for att in attention])\n        assert all([\n            att.start_time() == series_.end_time() - (icl - 1) * freq\n            for att, series_ in zip(attention, series)\n        ])\n        assert all([\n            att.end_time() == series_.end_time() + ocl * freq\n            for att, series_ in zip(attention, series)\n        ])\n        assert all([att.n_components == ocl for att in attention])\n"
    },
    {
      "id": "unit8co_darts_1611_1",
      "input_code": "    def test_explainer_single_univariate_multivariate_series(self, test_case):\n        \n        series_option, cov_option, add_relative_idx, use_encoders = test_case\n        series, pc, fc = self.helper_get_input(series_option)\n        cov_test_case = dict()\n        use_pc, use_fc = False, False\n        if \"past_covariates\" in cov_option:\n            cov_test_case[\"past_covariates\"] = pc\n            use_pc = True\n        if \"future_covariates\" in cov_option:\n            cov_test_case[\"future_covariates\"] = fc\n            use_fc = True\n\n        n_target_expected = series.n_components\n        n_pc_expected = 1 if \"past_covariates\" in cov_test_case else 0\n        n_fc_expected = 1 if \"future_covariates\" in cov_test_case else 0\n        n_sc_expected = 2\n        n_enc_expected = (\n            n_pc_expected\n            + n_fc_expected\n            + n_target_expected\n            + (4 if use_encoders else 0)\n            + (1 if add_relative_idx else 0)\n        )\n        n_dec_expected = (\n            n_fc_expected + (2 if use_encoders else 0) + (1 if add_relative_idx else 0)\n        )\n        model = self.helper_create_model(\n            use_encoders=use_encoders, add_relative_idx=add_relative_idx\n        )\n        if (\n            not add_relative_idx\n            and \"future_covariates\" not in cov_test_case\n            and not use_encoders\n        ):\n            with pytest.raises(ValueError):\n                model.fit(series=series, **cov_test_case)\n            return\n\n        model.fit(series=series, **cov_test_case)\n        explainer = TFTExplainer(model)\n        explainer2 = TFTExplainer(\n            model,\n            background_series=series,\n            background_past_covariates=pc if use_pc else None,\n            background_future_covariates=fc if use_fc else None,\n        )\n        assert explainer.background_series == explainer2.background_series\n        assert (\n            explainer.background_past_covariates\n            == explainer2.background_past_covariates\n        )\n        assert (\n            explainer.background_future_covariates\n            == explainer2.background_future_covariates\n        )\n\n        assert hasattr(explainer, \"model\")\n        assert explainer.background_series[0] == series\n        if use_pc:\n            assert explainer.background_past_covariates[0] == pc\n            assert explainer.background_past_covariates[0].n_components == n_pc_expected\n        else:\n            assert explainer.background_past_covariates is None\n        if use_fc:\n            assert explainer.background_future_covariates[0] == fc\n            assert (\n                explainer.background_future_covariates[0].n_components == n_fc_expected\n            )\n        else:\n            assert explainer.background_future_covariates is None\n        result = explainer.explain()\n        assert isinstance(result, TFTExplainabilityResult)\n\n        enc_imp = result.get_encoder_importance()\n        dec_imp = result.get_decoder_importance()\n        stc_imp = result.get_static_covariates_importance()\n        imps = [enc_imp, dec_imp, stc_imp]\n        assert all([isinstance(imp, pd.DataFrame) for imp in imps])\n        assert all([\n            imp.squeeze().sum() == pytest.approx(100.0, rel=0.2) for imp in imps\n        ])\n        assert all([\n            len(imp.columns) == n\n            for imp, n in zip(imps, [n_enc_expected, n_dec_expected, n_sc_expected])\n        ])\n\n        attention = result.get_attention()\n        assert isinstance(attention, TimeSeries)\n        icl, ocl = 5, 2\n        freq = series.freq\n        assert len(attention) == icl + ocl\n        assert attention.start_time() == series.end_time() - (icl - 1) * freq\n        assert attention.end_time() == series.end_time() + ocl * freq\n        assert attention.n_components == ocl\n"
    }
  ],
  "generated_inputs": [
    "<needimport>\nimport numpy as np\nimport pandas as pd\nfrom unittest.mock import patch\nimport pytest\nimport matplotlib.pyplot as plt\nfrom darts.models import TFTModel\nfrom darts.explainability import TFTExplainer, TFTExplainabilityResult\nfrom darts.timeseries import TimeSeries\n\n<testcase_1>\nuse_encoders = True\nadd_relative_idx = True\nfull_attention = False\n\n<testcase_2>\nuse_encoders = False\nadd_relative_idx = True\nfull_attention = True\n\n<testcase_3>\nuse_encoders = True\nadd_relative_idx = False\nfull_attention = True\n\n<testcase_4>\nuse_encoders = False\nadd_relative_idx = False\nfull_attention = False\n\n<testcase_5>\nuse_encoders = True\nadd_relative_idx = True\nfull_attention = True"
  ],
  "gpt_output": "<needimport>\nimport numpy as np\nimport pandas as pd\nfrom unittest.mock import patch\nimport pytest\nimport matplotlib.pyplot as plt\nfrom darts.models import TFTModel\nfrom darts.explainability import TFTExplainer, TFTExplainabilityResult\nfrom darts.timeseries import TimeSeries\n\n<testcase_1>\nuse_encoders = True\nadd_relative_idx = True\nfull_attention = False\n\n<testcase_2>\nuse_encoders = False\nadd_relative_idx = True\nfull_attention = True\n\n<testcase_3>\nuse_encoders = True\nadd_relative_idx = False\nfull_attention = True\n\n<testcase_4>\nuse_encoders = False\nadd_relative_idx = False\nfull_attention = False\n\n<testcase_5>\nuse_encoders = True\nadd_relative_idx = True\nfull_attention = True",
  "needimport": "import numpy as np\nimport pandas as pd\nfrom unittest.mock import patch\nimport pytest\nimport matplotlib.pyplot as plt\nfrom darts.models import TFTModel\nfrom darts.explainability import TFTExplainer, TFTExplainabilityResult\nfrom darts.timeseries import TimeSeries\n\n",
  "test_results": {
    "ans1": {
      "input_chunk_length": 5,
      "output_chunk_length": 2,
      "n_epochs": 1,
      "add_encoders": {
        "cyclic": {
          "past": [
            "month"
          ],
          "future": [
            "month"
          ]
        }
      },
      "add_relative_index": true,
      "full_attention": false
    },
    "ans2": {
      "input_chunk_length": 5,
      "output_chunk_length": 2,
      "n_epochs": 1,
      "add_encoders": null,
      "add_relative_index": true,
      "full_attention": true
    },
    "ans3": {
      "input_chunk_length": 5,
      "output_chunk_length": 2,
      "n_epochs": 1,
      "add_encoders": {
        "cyclic": {
          "past": [
            "month"
          ],
          "future": [
            "month"
          ]
        }
      },
      "add_relative_index": false,
      "full_attention": true
    },
    "ans4": {
      "input_chunk_length": 5,
      "output_chunk_length": 2,
      "n_epochs": 1,
      "add_encoders": null,
      "add_relative_index": false,
      "full_attention": false
    },
    "ans5": {
      "input_chunk_length": 5,
      "output_chunk_length": 2,
      "n_epochs": 1,
      "add_encoders": {
        "cyclic": {
          "past": [
            "month"
          ],
          "future": [
            "month"
          ]
        }
      },
      "add_relative_index": true,
      "full_attention": true
    }
  }
}