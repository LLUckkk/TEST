{
  "input_header": "def convert_pad_shape(pad_shape):",
  "input_docstring": null,
  "output_code": "def convert_pad_shape(pad_shape):\n    layer = pad_shape[::-1]\n    pad_shape = [item for sublist in layer for item in sublist]\n    return pad_shape",
  "input_contexts": [
    {
      "id": "myshell-ai_OpenVoice_38_3",
      "input_code": "    def _absolute_position_to_relative_position(self, x):\n        \n        batch, heads, length, _ = x.size()\n        x = F.pad(\n            x, commons.convert_pad_shape([[0, 0], [0, 0], [0, 0], [0, length - 1]])\n        )\n        x_flat = x.view([batch, heads, length**2 + length * (length - 1)])\n        x_flat = F.pad(x_flat, commons.convert_pad_shape([[0, 0], [0, 0], [length, 0]]))\n        x_final = x_flat.view([batch, heads, length, 2 * length])[:, :, :, 1:]\n        return x_final\n"
    },
    {
      "id": "myshell-ai_OpenVoice_38_7",
      "input_code": "def generate_path(duration, mask):\n    \n\n    b, _, t_y, t_x = mask.shape\n    cum_duration = torch.cumsum(duration, -1)\n\n    cum_duration_flat = cum_duration.view(b * t_x)\n    path = sequence_mask(cum_duration_flat, t_y).to(mask.dtype)\n    path = path.view(b, t_x, t_y)\n    path = path - F.pad(path, convert_pad_shape([[0, 0], [1, 0], [0, 0]]))[:, :-1]\n    path = path.unsqueeze(1).transpose(2, 3) * mask\n    return path\n"
    },
    {
      "id": "myshell-ai_OpenVoice_38_1",
      "input_code": "    def _get_relative_embeddings(self, relative_embeddings, length):\n        2 * self.window_size + 1\n        pad_length = max(length - (self.window_size + 1), 0)\n        slice_start_position = max((self.window_size + 1) - length, 0)\n        slice_end_position = slice_start_position + 2 * length - 1\n        if pad_length > 0:\n            padded_relative_embeddings = F.pad(\n                relative_embeddings,\n                commons.convert_pad_shape([[0, 0], [pad_length, pad_length], [0, 0]]),\n            )\n        else:\n            padded_relative_embeddings = relative_embeddings\n        used_relative_embeddings = padded_relative_embeddings[\n            :, slice_start_position:slice_end_position\n        ]\n        return used_relative_embeddings\n"
    },
    {
      "id": "myshell-ai_OpenVoice_38_5",
      "input_code": "    def _same_padding(self, x):\n        if self.kernel_size == 1:\n            return x\n        pad_l = (self.kernel_size - 1) // 2\n        pad_r = self.kernel_size // 2\n        padding = [[0, 0], [0, 0], [pad_l, pad_r]]\n        x = F.pad(x, commons.convert_pad_shape(padding))\n        return x\n"
    },
    {
      "id": "myshell-ai_OpenVoice_38_2",
      "input_code": "    def _relative_position_to_absolute_position(self, x):\n        \n        batch, heads, length, _ = x.size()\n        x = F.pad(x, commons.convert_pad_shape([[0, 0], [0, 0], [0, 0], [0, 1]]))\n\n        x_flat = x.view([batch, heads, length * 2 * length])\n        x_flat = F.pad(\n            x_flat, commons.convert_pad_shape([[0, 0], [0, 0], [0, length - 1]])\n        )\n\n        x_final = x_flat.view([batch, heads, length + 1, 2 * length - 1])[\n            :, :, :length, length - 1 :\n        ]\n        return x_final\n"
    },
    {
      "id": "myshell-ai_OpenVoice_38_4",
      "input_code": "    def _causal_padding(self, x):\n        if self.kernel_size == 1:\n            return x\n        pad_l = self.kernel_size - 1\n        pad_r = 0\n        padding = [[0, 0], [0, 0], [pad_l, pad_r]]\n        x = F.pad(x, commons.convert_pad_shape(padding))\n        return x\n"
    },
    {
      "id": "myshell-ai_OpenVoice_38_6",
      "input_code": "def shift_1d(x):\n    x = F.pad(x, convert_pad_shape([[0, 0], [0, 0], [1, 0]]))[:, :, :-1]\n    return x\n"
    }
  ],
  "generated_inputs": [
    "<needimport>\nimport torch.nn.functional as F\n\n<testcase_1>\npad_shape = [[0, 0], [1, 0], [0, 0]]\n\n<testcase_2>\npad_shape = [[0, 0], [0, 0], [0, 0], [0, 1]]\n\n<testcase_3>\npad_shape = [[0, 0], [0, 0], [0, 0], [0, 5]]\n\n<testcase_4>\npad_shape = [[0, 0], [0, 0], [2, 3]]\n\n<testcase_5>\npad_shape = [[0, 0], [0, 0], [1, 0], [0, 4]]"
  ],
  "gpt_output": "<needimport>\nimport torch.nn.functional as F\n\n<testcase_1>\npad_shape = [[0, 0], [1, 0], [0, 0]]\n\n<testcase_2>\npad_shape = [[0, 0], [0, 0], [0, 0], [0, 1]]\n\n<testcase_3>\npad_shape = [[0, 0], [0, 0], [0, 0], [0, 5]]\n\n<testcase_4>\npad_shape = [[0, 0], [0, 0], [2, 3]]\n\n<testcase_5>\npad_shape = [[0, 0], [0, 0], [1, 0], [0, 4]]",
  "needimport": "import torch.nn.functional as F\n\n",
  "test_results": {
    "ans1": [
      0,
      0,
      1,
      0,
      0,
      0
    ],
    "ans2": [
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "ans3": [
      0,
      5,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "ans4": [
      2,
      3,
      0,
      0,
      0,
      0
    ],
    "ans5": [
      0,
      4,
      1,
      0,
      0,
      0,
      0,
      0
    ]
  }
}