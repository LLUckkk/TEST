{
  "input_header": "def dump_dict(dict_obj: dict, flavor: str = \"dmlc\") -> str:",
  "input_docstring": "Dump the config to string.\n\nParameters\n----------\nsrc_dict: dict\n    The source dict.\nflavor: str\n    The flavor for dumps.\n\nReturns\n-------\nstr_dict: string\n    The dumped string.",
  "output_code": "def dump_dict(dict_obj: dict, flavor: str = \"dmlc\") -> str:\n    \n\n    if not dict_obj:\n        return \"\"\n    if flavor == \"dmlc\":\n        return json.dumps({k: int(v) if isinstance(v, bool) else v for k, v in dict_obj.items()})\n    if flavor.startswith(\"table:\"):\n\n        def _get_lines(value, indent=2):\n            max_size = int(flavor.split(\":\")[1]) - indent - 2\n            lines = []\n            for k, v in value.items():\n                if v is None:\n                    continue\n                if isinstance(v, (dict, tuple, list)) and not v:\n                    continue\n                if isinstance(v, dict) and len(str(k) + str(v)) > max_size:\n                    lines.append(\"{}{}:\".format(indent * \" \", k))\n                    lines.extend(_get_lines(v, indent + 2))\n                elif isinstance(v, (tuple, list)) and len(str(k) + str(v)) > max_size:\n                    if MSCArray.is_array(v):\n                        lines.append(\"{}{}: {}\".format(indent * \" \", k, MSCArray(v).abstract()))\n                    else:\n                        lines.append(\"{}{}:\".format(indent * \" \", k))\n                        for idx, ele in enumerate(v):\n                            if isinstance(ele, dict) and len(str(ele)) > max_size:\n                                lines.append(\"{}[{}.{}]:\".format((indent + 2) * \" \", k, idx))\n                                lines.extend(_get_lines(ele, indent + 4))\n                            else:\n                                lines.append(\"{}<{}>{}\".format((indent + 2) * \" \", idx, ele))\n                elif isinstance(v, bool):\n                    lines.append(\"{}{}: {}\".format(indent * \" \", k, \"true\" if v else \"false\"))\n                elif MSCArray.is_array(v):\n                    lines.append(\"{}{}: {}\".format(indent * \" \", k, MSCArray(v).abstract()))\n                elif hasattr(v, \"__name__\"):\n                    lines.append(\"{}{}: {}({})\".format(indent * \" \", k, v.__name__, type(v)))\n                else:\n                    lines.append(\"{}{}: {}\".format(indent * \" \", k, v))\n            return lines\n\n        lines = _get_lines(dict_obj) or [\"  {}: {}\".format(k, v) for k, v in dict_obj.items()]\n        return \"\\n\".join(lines)\n    return json.dumps(dict_obj)",
  "input_contexts": [
    {
      "id": "apache_tvm_2165_1",
      "input_code": "    def __init__(\n        self,\n        graph: MSCGraph,\n        source_getter: Callable[[MSCGraph, str, str], str],\n        codegen_config: Optional[Dict[str, str]] = None,\n        print_config: Optional[Dict[str, str]] = None,\n        build_folder: msc_utils.MSCDirectory = None,\n        code_format: str = \"python\",\n    ):\n        self._graph = graph\n        self._source_getter = source_getter\n        self._codegen_config = msc_utils.dump_dict(codegen_config)\n        self._print_config = msc_utils.dump_dict(print_config)\n        self._build_folder = build_folder or msc_utils.msc_dir(keep_history=False, cleanup=True)\n        self._code_format = code_format\n"
    },
    {
      "id": "apache_tvm_2165_4",
      "input_code": "def byoc_partition(\n    target: str,\n    mod: tvm.IRModule,\n    params: Optional[Dict[str, tvm.nd.array]] = None,\n    trans_config: Optional[Dict[str, str]] = None,\n    build_config: Optional[Dict[str, str]] = None,\n) -> Tuple[tvm.IRModule, List[Tuple[MSCGraph, Dict[str, tvm.nd.array]]]]:\n    \n\n    trans_config = msc_utils.copy_dict(trans_config)\n    build_config = msc_utils.copy_dict(build_config)\n    build_config[\"target\"] = target\n    for key in [\"input_aliases\", \"output_aliases\"]:\n        if key in build_config:\n            build_config.pop(key)\n    entry = trans_config.get(\"entry\", \"main\")\n    if params:\n        mod = BindParams(\"main\", params)(mod)\n\n    def _partition_mod(mod, as_msc=True):\n        patterns = get_patterns_with_prefix(target)\n        passes = [\n            tvm.relax.transform.ExpandTupleArguments(),\n            msc_transform.SetExprName(),\n            msc_transform.SetExprLayout(trans_config.get(\"allow_layout_missing\", True)),\n            tvm.relax.transform.FuseOpsByPattern(patterns, bind_constants=not as_msc),\n            msc_transform.InlineParams(),\n            msc_transform.FuseTuple(target),\n            tvm.relax.transform.MergeCompositeFunctions(),\n            msc_transform.SetBYOCAttrs(target),\n        ]\n        return tvm.transform.Sequential(passes)(mod)\n\n    def _is_target_func(func):\n        if \"Codegen\" not in func.attrs:\n            return False\n        return func.attrs[\"Codegen\"] == target\n\n    msc_mod = _partition_mod(mod)\n    func_names = [var.name_hint for var, func in msc_mod.functions.items() if _is_target_func(func)]\n\n    if trans_config.get(\"as_complete\", True):\n        assert len(func_names) == 1, \"More than 1 target func is found: \" + str(msc_mod)\n        BYOCChecker().check(func_names, msc_mod[entry])\n\n    ref_weights = _ffi_api.GetRelaxWeights(msc_mod, entry)\n    graphs, weights = [], {}\n    for name in func_names:\n        graph_name = msc_mod[name].attrs[_ffi_api.ToAttrKey(\"unique\")]\n        build_config.update({\"graph_name\": graph_name, \"byoc_entry\": name})\n        graph = _ffi_api.BuildFromRelax(msc_mod, entry, msc_utils.dump_dict(build_config))\n        graphs.append(graph)\n        weights.update(normalize_weights(ref_weights, graph))\n    return _partition_mod(mod, False), graphs, weights\n"
    },
    {
      "id": "apache_tvm_2165_13",
      "input_code": "    def __init__(\n        self,\n        workspace: msc_utils.MSCDirectory,\n        codegen_config: Optional[Dict[str, str]] = None,\n        cpp_print_config: Optional[Dict[str, str]] = None,\n        py_print_config: Optional[Dict[str, str]] = None,\n        extern_sources: Dict[str, str] = None,\n        extern_libs: Dict[str, str] = None,\n        on_debug: bool = False,\n    ):\n        self._codegen_config = msc_utils.copy_dict(codegen_config)\n        self._cpp_print_config = msc_utils.dump_dict(cpp_print_config)\n        self._py_print_config = msc_utils.dump_dict(py_print_config)\n        self._build_folder = workspace.create_dir(\n            \"source_\" + self.framework, keep_history=on_debug, cleanup=not on_debug\n        )\n        self._output_folder = workspace.create_dir(self.framework)\n        self._extern_sources = extern_sources or {}\n        self._extern_libs = extern_libs or {}\n        self.setup()\n"
    },
    {
      "id": "apache_tvm_2165_3",
      "input_code": "def from_relay(\n    mod: tvm.IRModule,\n    params: Optional[Dict[str, tvm.nd.array]] = None,\n    trans_config: Optional[Dict[str, str]] = None,\n    build_config: Optional[Dict[str, str]] = None,\n    opt_config: Optional[Dict[str, str]] = None,\n) -> Tuple[MSCGraph, Dict[str, tvm.nd.array]]:\n    \n\n    trans_config = msc_utils.copy_dict(trans_config)\n    build_config = msc_utils.copy_dict(build_config)\n    opt_config = msc_utils.copy_dict(opt_config)\n    opt_level = opt_config.get(\"opt_level\", 0)\n    if params:\n        mod[\"main\"] = bind_params_by_name(mod[\"main\"], params)\n    if opt_level > 0:\n        target = opt_config.get(\"target\", \"llvm\")\n        disabled_pass = opt_config.get(\"disabled_pass\", []) + [\n            \"SimplifyInference\",\n            \"CanonicalizeOps\",\n            \"FuseOps\",\n            \"AlterOpLayout\",\n        ]\n        with tvm.transform.PassContext(opt_level=opt_level, disabled_pass=disabled_pass):\n            mod, params = tvm.relay.optimize(mod, target=target, params=params)\n    patterns = get_relay_patterns(mod)\n    passes = [\n        tvm.relay.transform.InferType(),\n        tvm.relay.transform.MergeComposite(patterns),\n        msc_transform.SetExprName(as_relax=False),\n    ]\n    mod = tvm.transform.Sequential(passes)(mod)\n    graph = _ffi_api.BuildFromRelay(mod, \"main\", msc_utils.dump_dict(build_config))\n    t_weights = _ffi_api.GetRelayWeights(mod, \"main\")\n    return graph, normalize_weights(t_weights, graph)\n"
    },
    {
      "id": "apache_tvm_2165_8",
      "input_code": "    def _translate(self, mod: tvm.IRModule) -> Tuple[List[MSCGraph], Dict[str, tvm.nd.array]]:\n        \n\n        self._byoc_mod, graphs, weights = self.partition_func(\n            mod,\n            trans_config=self._translate_config.get(\"transform\"),\n            build_config=self._translate_config.get(\"build\"),\n        )\n        self._byoc_graph = _ffi_api.BuildFromRelax(\n            self._byoc_mod, \"main\", msc_utils.dump_dict(self._translate_config.get(\"build\"))\n        )\n        return graphs, weights\n"
    },
    {
      "id": "apache_tvm_2165_10",
      "input_code": "def to_tensorrt(\n    mod: tvm.IRModule,\n    graphs: List[MSCGraph],\n    weights: Dict[str, tvm.nd.array],\n    codegen_configs: Optional[Union[Dict[str, str], List[Dict[str, str]]]] = None,\n    print_configs: Optional[Union[Dict[str, str], List[Dict[str, str]]]] = None,\n    extra_options: Optional[Union[Dict[str, str], List[Dict[str, str]]]] = None,\n    build_folder: msc_utils.MSCDirectory = None,\n    output_folder: msc_utils.MSCDirectory = None,\n    plugin: Any = None,\n) -> Dict[str, str]:\n    \n\n    target_options = {}\n    if not isinstance(codegen_configs, (list, tuple)):\n        codegen_configs = [codegen_configs] * len(graphs)\n    if not isinstance(print_configs, (list, tuple)):\n        print_configs = [print_configs] * len(graphs)\n    if not isinstance(extra_options, (list, tuple)):\n        extra_options = [extra_options] * len(graphs)\n    for idx, graph in enumerate(graphs):\n        options = to_sub_tensorrt(\n            graph,\n            weights,\n            codegen_configs[idx],\n            print_configs[idx],\n            build_folder,\n            output_folder,\n            plugin=plugin,\n        )\n        if extra_options[idx]:\n            options.update(extra_options[idx])\n        target_options[graph.name] = msc_utils.dump_dict(options)\n    mod = tvm.transform.Sequential(\n        [\n            tvm.relax.transform.RunCodegen({\"msc_tensorrt\": target_options}),\n        ]\n    )(mod)\n    return mod\n"
    },
    {
      "id": "apache_tvm_2165_2",
      "input_code": "def from_relax(\n    mod: tvm.IRModule,\n    params: Optional[Dict[str, tvm.nd.array]] = None,\n    trans_config: Optional[Dict[str, str]] = None,\n    build_config: Optional[Dict[str, str]] = None,\n    opt_config: Optional[Dict[str, str]] = None,\n) -> Tuple[MSCGraph, Dict[str, tvm.nd.array]]:\n    \n\n    trans_config = msc_utils.copy_dict(trans_config)\n    build_config = msc_utils.copy_dict(build_config)\n    opt_config = msc_utils.copy_dict(opt_config)\n    entry = trans_config.get(\"entry\", \"main\")\n    if params:\n        mod = BindParams(\"main\", params)(mod)\n    opt_level = opt_config.get(\"opt_level\", 1)\n    if opt_level > 0:\n        mod = tvm.transform.Sequential(\n            [\n                tvm.relax.transform.FoldConstant(),\n            ]\n        )(mod)\n    patterns = get_patterns_with_prefix(\"msc.\")\n    passes = [\n        tvm.relax.transform.ExpandTupleArguments(),\n        msc_transform.SetExprName(),\n        msc_transform.SetExprLayout(trans_config.get(\"allow_layout_missing\", True)),\n        tvm.relax.transform.FuseOpsByPattern(\n            patterns, bind_constants=False, annotate_codegen=False\n        ),\n    ]\n    mod = tvm.transform.Sequential(passes)(mod)\n    graph = _ffi_api.BuildFromRelax(mod, entry, msc_utils.dump_dict(build_config))\n    t_weights = _ffi_api.GetRelaxWeights(mod, entry)\n    return graph, normalize_weights(t_weights, graph)\n"
    },
    {
      "id": "apache_tvm_2165_6",
      "input_code": "    def from_json(cls, json_str: str) -> BaseGraph:\n        \n\n        dict_obj = msc_utils.load_dict(json_str)\n        return _ffi_api.MSCGraphFromJson(msc_utils.dump_dict(dict_obj))\n"
    },
    {
      "id": "apache_tvm_2165_7",
      "input_code": "    def from_json(cls, json_str: str) -> BaseGraph:\n        \n\n        dict_obj = msc_utils.load_dict(json_str)\n        return _ffi_api.WeightGraphFromJson(msc_utils.dump_dict(dict_obj))\n"
    },
    {
      "id": "apache_tvm_2165_15",
      "input_code": "    def build_manager(self, ops_info: dict) -> List[str]:\n        \n\n        self._codegen_config[\"libs\"] = self._libs\n        self._codegen_config[\"ops_info\"] = {n: msc_utils.dump_dict(i) for n, i in ops_info.items()}\n        codegen_config = msc_utils.dump_dict(self._codegen_config)\n        sources = self.source_getter(codegen_config, self._py_print_config, \"manager\")\n        manager_files = []\n        with self._manager_folder as folder:\n            for name, source in sources.items():\n                manager_files.append(folder.add_file(name, source))\n        return manager_files\n"
    },
    {
      "id": "apache_tvm_2165_11",
      "input_code": "def TransformTensorRT(\n    version: List[int] = None, linear_to_conv: bool = False\n) -> tvm.ir.transform.Pass:\n    \n\n    config = {\n        \"version\": version or msc_utils.get_version(MSCFramework.TENSORRT),\n        \"linear_to_conv\": linear_to_conv,\n    }\n    return relax_api.TransformTensorRT(msc_utils.dump_dict(config))\n"
    },
    {
      "id": "apache_tvm_2165_5",
      "input_code": "    def from_json(cls, json_str: str, **options) -> object:\n        \n\n        dict_obj = msc_utils.load_dict(json_str)\n        dict_obj.update(options)\n        return _ffi_api.MSCTensorFromJson(msc_utils.dump_dict(dict_obj))\n"
    },
    {
      "id": "apache_tvm_2165_16",
      "input_code": "def register_plugin(\n    name: str, plugin: dict, externs_dir: msc_utils.MSCDirectory = None\n) -> Dict[str, str]:\n    \n\n    plugin = {\"name\": name, **msc_utils.load_dict(plugin)}\n    assert \"externs\" in plugin, \"externs are needed to build plugin\"\n    remove_externs = set()\n    for extern in plugin[\"externs\"]:\n        if extern == \"cuda_compute\" and not tvm.cuda().exist:\n            remove_externs.add(extern)\n    if remove_externs:\n        plugin[\"externs\"] = {k: v for k, v in plugin[\"externs\"].items() if k not in remove_externs}\n    externs = plugin[\"externs\"]\n\n    def _check_file(info: dict, key: str) -> str:\n        if key not in info:\n            return None\n        file_path = info[key]\n        if os.path.abspath(file_path) != file_path:\n            assert externs_dir, \"externs_dir is need to find file \" + str(file_path)\n            file_path = externs_dir.relpath(file_path)\n        assert os.path.isfile(file_path), \"Can not find externs file \" + str(file_path)\n        info[key] = os.path.basename(file_path)\n        return file_path\n\n    extern_sources, extern_libs = {}, {}\n    for info in externs.values():\n        for key in [\"header\", \"source\"]:\n            file_path = _check_file(info, key)\n            if file_path:\n                extern_sources[os.path.basename(file_path)] = file_path\n        file_path = _check_file(info, \"lib\")\n        if file_path:\n            extern_libs[os.path.basename(file_path)] = file_path\n    _ffi_api.RegisterPlugin(name, msc_utils.dump_dict(plugin))\n    for key in [\"support_dtypes\", \"externs\"]:\n        plugin.pop(key)\n    plugin[\"inputs\"] = [{\"name\": i[\"name\"]} for i in plugin[\"inputs\"]]\n    plugin[\"outputs\"] = [{\"name\": o[\"name\"]} for o in plugin[\"outputs\"]]\n    return extern_sources, extern_libs, plugin\n"
    },
    {
      "id": "apache_tvm_2165_9",
      "input_code": "def msg_block(title: str, msg: str, width: int = 100, symbol: str = \"-\"):\n    \n\n    if isinstance(msg, dict):\n        msg = dump_dict(msg, \"table:\" + str(width))\n    return \"{}\\n{}\".format(split_line(title, symbol), msg)\n"
    },
    {
      "id": "apache_tvm_2165_12",
      "input_code": "    def setup(self) -> dict:\n        \n\n        self._model_type = self._config[\"model_type\"]\n        self._optimize_type = self._config.get(MSCStage.OPTIMIZE, {}).get(\n            \"run_type\", self._model_type\n        )\n        self._compile_type = self._config.get(MSCStage.COMPILE, {}).get(\n            \"run_type\", self._model_type\n        )\n        self._optimized, self._compiled = False, False\n\n        self._tools_config = map_tools(self._config.get(\"tools\", []))\n\n        if self._plugins:\n            for t in [self._model_type, self._optimize_type, self._compile_type]:\n                assert t in self._plugins, \"Missing plugin for {}\".format(t)\n            for name, plugin in self._plugins[self._model_type].get_ops_info().items():\n                _ffi_api.RegisterPlugin(name, msc_utils.dump_dict(plugin))\n\n        self._current_stage = None\n        self._report = {\n            \"success\": False,\n            \"info\": {},\n            \"duration\": {},\n        }\n        return {\n            \"workspace\": self._workspace.path,\n            \"log_file\": msc_utils.get_log_file(self._logger),\n            \"verbose\": self._verbose,\n            \"plugins\": self._plugins,\n            \"config\": self._config,\n        }\n"
    },
    {
      "id": "apache_tvm_2165_14",
      "input_code": "    def build_libs(self) -> List[str]:\n        \n\n        codegen_config = msc_utils.dump_dict(self._codegen_config)\n        sources = self.source_getter(codegen_config, self._cpp_print_config, \"build\")\n        with self._build_folder as folder:\n            with folder.create_dir(\"src\") as src_folder:\n                for name, file in self._extern_sources.items():\n                    src_folder.copy(file, name)\n                for name, source in get_plugin_sources().items():\n                    src_folder.add_file(name, source)\n                for name, source in sources.items():\n                    if name == \"CMakeLists.txt\":\n                        folder.add_file(name, source)\n                    else:\n                        src_folder.add_file(name, source)\n            with folder.create_dir(\"build\"):\n                command = \"cmake ../ && make\"\n                with open(\"codegen.log\", \"w\") as log_f:\n                    process = subprocess.Popen(command, stdout=log_f, stderr=log_f, shell=True)\n                process.wait()\n                assert (\n                    process.returncode == 0\n                ), \"Failed to build plugin under {}, check codegen.log for detail\".format(\n                    os.getcwd()\n                )\n            self._libs.extend([os.path.basename(l) for l in self._lib_folder.listdir()])\n        return self._lib_folder.listdir(as_abs=True)\n"
    }
  ],
  "generated_inputs": [
    "<needimport>\nimport json\n\n<testcase_1>\ndict_obj = {\"key1\": \"value1\", \"key2\": 123, \"key3\": True}\nflavor = \"dmlc\"\n\n<testcase_2>\ndict_obj = {\"name\": \"test\", \"active\": False, \"count\": 42}\nflavor = \"table:50\"\n\n<testcase_3>\ndict_obj = {\"item1\": [1, 2, 3], \"item2\": {\"subkey\": \"subvalue\"}, \"item3\": None}\nflavor = \"dmlc\"\n\n<testcase_4>\ndict_obj = {\"user\": \"admin\", \"permissions\": [\"read\", \"write\"], \"enabled\": True}\nflavor = \"table:80\"\n\n<testcase_5>\ndict_obj = {\"config\": {\"setting1\": \"on\", \"setting2\": \"off\"}, \"status\": \"active\"}\nflavor = \"dmlc\""
  ],
  "gpt_output": "<needimport>\nimport json\n\n<testcase_1>\ndict_obj = {\"key1\": \"value1\", \"key2\": 123, \"key3\": True}\nflavor = \"dmlc\"\n\n<testcase_2>\ndict_obj = {\"name\": \"test\", \"active\": False, \"count\": 42}\nflavor = \"table:50\"\n\n<testcase_3>\ndict_obj = {\"item1\": [1, 2, 3], \"item2\": {\"subkey\": \"subvalue\"}, \"item3\": None}\nflavor = \"dmlc\"\n\n<testcase_4>\ndict_obj = {\"user\": \"admin\", \"permissions\": [\"read\", \"write\"], \"enabled\": True}\nflavor = \"table:80\"\n\n<testcase_5>\ndict_obj = {\"config\": {\"setting1\": \"on\", \"setting2\": \"off\"}, \"status\": \"active\"}\nflavor = \"dmlc\"",
  "needimport": "import json\n\n",
  "test_results": {
    "ans1": "{\"key1\": \"value1\", \"key2\": 123, \"key3\": 1}",
    "ans2": null,
    "ans3": "{\"item1\": [1, 2, 3], \"item2\": {\"subkey\": \"subvalue\"}, \"item3\": null}",
    "ans4": null,
    "ans5": "{\"config\": {\"setting1\": \"on\", \"setting2\": \"off\"}, \"status\": \"active\"}"
  }
}