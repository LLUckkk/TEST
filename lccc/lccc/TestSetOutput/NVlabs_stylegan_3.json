{
  "input_header": "def choose_shuffled_order(self):",
  "input_docstring": null,
  "output_code": "    def choose_shuffled_order(self):\n        order = np.arange(self.expected_images)\n        np.random.RandomState(123).shuffle(order)\n        return order",
  "input_contexts": [
    {
      "id": "NVlabs_stylegan_3_3",
      "input_code": "def create_cifar100(tfrecord_dir, cifar100_dir):\n    print('Loading CIFAR-100 from \"%s\"' % cifar100_dir)\n    import pickle\n    with open(os.path.join(cifar100_dir, 'train'), 'rb') as file:\n        data = pickle.load(file, encoding='latin1')\n    images = data['data'].reshape(-1, 3, 32, 32)\n    labels = np.array(data['fine_labels'])\n    assert images.shape == (50000, 3, 32, 32) and images.dtype == np.uint8\n    assert labels.shape == (50000,) and labels.dtype == np.int32\n    assert np.min(images) == 0 and np.max(images) == 255\n    assert np.min(labels) == 0 and np.max(labels) == 99\n    onehot = np.zeros((labels.size, np.max(labels) + 1), dtype=np.float32)\n    onehot[np.arange(labels.size), labels] = 1.0\n\n    with TFRecordExporter(tfrecord_dir, images.shape[0]) as tfr:\n        order = tfr.choose_shuffled_order()\n        for idx in range(order.size):\n            tfr.add_image(images[order[idx]])\n        tfr.add_labels(onehot[order])\n"
    },
    {
      "id": "NVlabs_stylegan_3_2",
      "input_code": "def create_cifar10(tfrecord_dir, cifar10_dir):\n    print('Loading CIFAR-10 from \"%s\"' % cifar10_dir)\n    import pickle\n    images = []\n    labels = []\n    for batch in range(1, 6):\n        with open(os.path.join(cifar10_dir, 'data_batch_%d' % batch), 'rb') as file:\n            data = pickle.load(file, encoding='latin1')\n        images.append(data['data'].reshape(-1, 3, 32, 32))\n        labels.append(data['labels'])\n    images = np.concatenate(images)\n    labels = np.concatenate(labels)\n    assert images.shape == (50000, 3, 32, 32) and images.dtype == np.uint8\n    assert labels.shape == (50000,) and labels.dtype == np.int32\n    assert np.min(images) == 0 and np.max(images) == 255\n    assert np.min(labels) == 0 and np.max(labels) == 9\n    onehot = np.zeros((labels.size, np.max(labels) + 1), dtype=np.float32)\n    onehot[np.arange(labels.size), labels] = 1.0\n\n    with TFRecordExporter(tfrecord_dir, images.shape[0]) as tfr:\n        order = tfr.choose_shuffled_order()\n        for idx in range(order.size):\n            tfr.add_image(images[order[idx]])\n        tfr.add_labels(onehot[order])\n"
    },
    {
      "id": "NVlabs_stylegan_3_4",
      "input_code": "def create_svhn(tfrecord_dir, svhn_dir):\n    print('Loading SVHN from \"%s\"' % svhn_dir)\n    import pickle\n    images = []\n    labels = []\n    for batch in range(1, 4):\n        with open(os.path.join(svhn_dir, 'train_%d.pkl' % batch), 'rb') as file:\n            data = pickle.load(file, encoding='latin1')\n        images.append(data[0])\n        labels.append(data[1])\n    images = np.concatenate(images)\n    labels = np.concatenate(labels)\n    assert images.shape == (73257, 3, 32, 32) and images.dtype == np.uint8\n    assert labels.shape == (73257,) and labels.dtype == np.uint8\n    assert np.min(images) == 0 and np.max(images) == 255\n    assert np.min(labels) == 0 and np.max(labels) == 9\n    onehot = np.zeros((labels.size, np.max(labels) + 1), dtype=np.float32)\n    onehot[np.arange(labels.size), labels] = 1.0\n\n    with TFRecordExporter(tfrecord_dir, images.shape[0]) as tfr:\n        order = tfr.choose_shuffled_order()\n        for idx in range(order.size):\n            tfr.add_image(images[order[idx]])\n        tfr.add_labels(onehot[order])\n"
    },
    {
      "id": "NVlabs_stylegan_3_7",
      "input_code": "def create_from_hdf5(tfrecord_dir, hdf5_filename, shuffle):\n    print('Loading HDF5 archive from \"%s\"' % hdf5_filename)\n    import h5py\n    with h5py.File(hdf5_filename, 'r') as hdf5_file:\n        hdf5_data = max([value for key, value in hdf5_file.items() if key.startswith('data')], key=lambda lod: lod.shape[3])\n        with TFRecordExporter(tfrecord_dir, hdf5_data.shape[0]) as tfr:\n            order = tfr.choose_shuffled_order() if shuffle else np.arange(hdf5_data.shape[0])\n            for idx in range(order.size):\n                tfr.add_image(hdf5_data[order[idx]])\n            npy_filename = os.path.splitext(hdf5_filename)[0] + '-labels.npy'\n            if os.path.isfile(npy_filename):\n                tfr.add_labels(np.load(npy_filename)[order])\n"
    },
    {
      "id": "NVlabs_stylegan_3_1",
      "input_code": "def create_mnist(tfrecord_dir, mnist_dir):\n    print('Loading MNIST from \"%s\"' % mnist_dir)\n    import gzip\n    with gzip.open(os.path.join(mnist_dir, 'train-images-idx3-ubyte.gz'), 'rb') as file:\n        images = np.frombuffer(file.read(), np.uint8, offset=16)\n    with gzip.open(os.path.join(mnist_dir, 'train-labels-idx1-ubyte.gz'), 'rb') as file:\n        labels = np.frombuffer(file.read(), np.uint8, offset=8)\n    images = images.reshape(-1, 1, 28, 28)\n    images = np.pad(images, [(0,0), (0,0), (2,2), (2,2)], 'constant', constant_values=0)\n    assert images.shape == (60000, 1, 32, 32) and images.dtype == np.uint8\n    assert labels.shape == (60000,) and labels.dtype == np.uint8\n    assert np.min(images) == 0 and np.max(images) == 255\n    assert np.min(labels) == 0 and np.max(labels) == 9\n    onehot = np.zeros((labels.size, np.max(labels) + 1), dtype=np.float32)\n    onehot[np.arange(labels.size), labels] = 1.0\n\n    with TFRecordExporter(tfrecord_dir, images.shape[0]) as tfr:\n        order = tfr.choose_shuffled_order()\n        for idx in range(order.size):\n            tfr.add_image(images[order[idx]])\n        tfr.add_labels(onehot[order])\n"
    },
    {
      "id": "NVlabs_stylegan_3_6",
      "input_code": "def create_from_images(tfrecord_dir, image_dir, shuffle):\n    print('Loading images from \"%s\"' % image_dir)\n    image_filenames = sorted(glob.glob(os.path.join(image_dir, '*')))\n    if len(image_filenames) == 0:\n        error('No input images found')\n\n    img = np.asarray(PIL.Image.open(image_filenames[0]))\n    resolution = img.shape[0]\n    channels = img.shape[2] if img.ndim == 3 else 1\n    if img.shape[1] != resolution:\n        error('Input images must have the same width and height')\n    if resolution != 2 ** int(np.floor(np.log2(resolution))):\n        error('Input image resolution must be a power-of-two')\n    if channels not in [1, 3]:\n        error('Input images must be stored as RGB or grayscale')\n\n    with TFRecordExporter(tfrecord_dir, len(image_filenames)) as tfr:\n        order = tfr.choose_shuffled_order() if shuffle else np.arange(len(image_filenames))\n        for idx in range(order.size):\n            img = np.asarray(PIL.Image.open(image_filenames[order[idx]]))\n            if channels == 1:\n                img = img[np.newaxis, :, :]\n            else:\n                img = img.transpose([2, 0, 1])\n            tfr.add_image(img)\n"
    },
    {
      "id": "NVlabs_stylegan_3_5",
      "input_code": "def create_celeba(tfrecord_dir, celeba_dir, cx=89, cy=121):\n    print('Loading CelebA from \"%s\"' % celeba_dir)\n    glob_pattern = os.path.join(celeba_dir, 'img_align_celeba_png', '*.png')\n    image_filenames = sorted(glob.glob(glob_pattern))\n    expected_images = 202599\n    if len(image_filenames) != expected_images:\n        error('Expected to find %d images' % expected_images)\n\n    with TFRecordExporter(tfrecord_dir, len(image_filenames)) as tfr:\n        order = tfr.choose_shuffled_order()\n        for idx in range(order.size):\n            img = np.asarray(PIL.Image.open(image_filenames[order[idx]]))\n            assert img.shape == (218, 178, 3)\n            img = img[cy - 64 : cy + 64, cx - 64 : cx + 64]\n            img = img.transpose(2, 0, 1)\n            tfr.add_image(img)\n"
    }
  ],
  "generated_inputs": [
    "<needimport>\nimport numpy as np\n\n<testcase_1>\nself = type('TFRecordExporter', (object,), {'expected_images': 10000})()\n\n<testcase_2>\nself = type('TFRecordExporter', (object,), {'expected_images': 50000})()\n\n<testcase_3>\nself = type('TFRecordExporter', (object,), {'expected_images': 73257})()\n\n<testcase_4>\nself = type('TFRecordExporter', (object,), {'expected_images': 60000})()\n\n<testcase_5>\nself = type('TFRecordExporter', (object,), {'expected_images': 202599})()"
  ],
  "gpt_output": "<needimport>\nimport numpy as np\n\n<testcase_1>\nself = type('TFRecordExporter', (object,), {'expected_images': 10000})()\n\n<testcase_2>\nself = type('TFRecordExporter', (object,), {'expected_images': 50000})()\n\n<testcase_3>\nself = type('TFRecordExporter', (object,), {'expected_images': 73257})()\n\n<testcase_4>\nself = type('TFRecordExporter', (object,), {'expected_images': 60000})()\n\n<testcase_5>\nself = type('TFRecordExporter', (object,), {'expected_images': 202599})()",
  "needimport": "import numpy as np\n\n",
  "test_results": {
    "ans1": "[2656  445 9505 ... 5218 1346 3582]",
    "ans2": "[11872 40828 36400 ... 17730 28030 15725]",
    "ans3": "[ 9469 19487 15873 ... 17730 28030 15725]",
    "ans4": "[29561 26640 24498 ... 28030 15725 52734]",
    "ans5": "[192183  65052 141756 ...  17730  28030  15725]"
  }
}