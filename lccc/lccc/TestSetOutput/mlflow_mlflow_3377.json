{
  "input_header": "def add_html(self, name: str, html_content: str) -> CardTab:",
  "input_docstring": "Adds html to the CardTab.\n\nArgs:\n    name: Name of the variable in the Jinja2 template.\n    html_content: The html to replace the named template variable.\n\nReturns:\n    The updated card instance.",
  "output_code": "    def add_html(self, name: str, html_content: str) -> CardTab:\n        \n        if name not in self._variables:\n            raise MlflowException(\n                f\"{name} is not a valid template variable defined in template: '{self.template}'\",\n                error_code=INVALID_PARAMETER_VALUE,\n            )\n        self._context[name] = html_content\n        return self",
  "input_contexts": [
    {
      "id": "mlflow_mlflow_3377_10",
      "input_code": "def test_verify_card_information():\n    profile_report = \"pandas-profiling\"\n    card = BaseCard(\n        recipe_name=\"fake recipe\",\n        step_name=\"fake step\",\n    )\n    (\n        card.add_tab(\n            \"First tab\",\n            \"\"\"\n        <h3 class=\"section-title\">Markdown:</h3>\n        {{ MARKDOWN_1 }}<hr>\n        <h3 class=\"section-title\">Other:</h3>\n        {{ HTML_1 }}\"\"\",\n        )\n        .add_markdown(\"MARKDOWN_1\", \"#### Hello, world!\")\n        .add_html(\"HTML_1\", \"<span style='color:blue'>blue</span>\")\n    )\n    card.add_tab(\"Profile 1\", \"{{PROFILE}}\").add_pandas_profile(\"PROFILE\", profile_report)\n    card.add_tab(\"Profile 2\", \"{{PROFILE}}\").add_pandas_profile(\"PROFILE\", profile_report)\n    card.add_text(\"1,2,3.\")\n\n    expected_html = \"\"\"\n        <h3 class=\"section-title\">Markdown:</h3>\n        <h4>Hello, world!</h4><hr>\n        <h3 class=\"section-title\">Other:</h3>\n        <span style='color:blue'>blue</span></div>\n    \"\"\"\n    assert expected_html in card.to_html()\n    assert card.to_text() == \"1,2,3.\"\n    assert all(card.get_tab(name) is not None for name in [\"Profile 1\", \"Profile 2\", \"First tab\"])\n    assert all(card.get_tab(name) is None for name in [\"\", \"!x\", \"fake tab 3\"])\n"
    },
    {
      "id": "mlflow_mlflow_3377_12",
      "input_code": "def test_card_tab_fails_with_invalid_variable():\n    with pytest.raises(MlflowException, match=r\"(not a valid template variable)\"):\n        CardTab(\"tab\", \"{{MARKDOWN_1}}\").add_html(\"HTML_1\", \"<span style='color:blue'>blue</span>\")\n"
    },
    {
      "id": "mlflow_mlflow_3377_6",
      "input_code": "    def _build_profiles_and_card(\n        self, run_id, model_uri, eval_metrics, validation_results, output_directory\n    ):\n        \n        import pandas as pd\n\n        card = BaseCard(self.recipe_name, self.name)\n        metric_df = (\n            get_merged_eval_metrics(\n                eval_metrics,\n                ordered_metric_names=[self.primary_metric, *self.user_defined_custom_metrics],\n            )\n            .reset_index()\n            .rename(columns={\"index\": \"Metric\"})\n        )\n\n        def row_style(row):\n            if row.Metric == self.primary_metric or row.Metric in self.user_defined_custom_metrics:\n                return pd.Series(\"font-weight: bold\", row.index)\n            else:\n                return pd.Series(\"\", row.index)\n\n        metric_table_html = BaseCard.render_table(\n            metric_df.style.format({\"training\": \"{:.6g}\", \"validation\": \"{:.6g}\"}).apply(\n                row_style, axis=1\n            )\n        )\n\n        card.add_tab(\n            \"Model Performance (Test)\",\n            \"<h3 class='section-title'>Summary Metrics</h3>\"\n            \"<b>NOTE</b>: Use evaluation metrics over test dataset with care. \"\n            \"Fine-tuning model over the test dataset is not advised.\"\n            \"{{ METRICS }} \",\n        ).add_html(\"METRICS\", metric_table_html)\n\n        if validation_results is not None:\n\n            def get_icon(validated):\n                return (\n                    \"\\u2705\"\n                    if validated\n                    else \"\\u274c\"\n                )\n\n            result_df = pd.DataFrame(validation_results).assign(\n                validated=lambda df: df[\"validated\"].map(get_icon)\n            )\n\n            criteria_html = BaseCard.render_table(\n                result_df.style.format({\"value\": \"{:.6g}\", \"threshold\": \"{:.6g}\"})\n            )\n            card.add_tab(\"Model Validation\", \"{{ METRIC_VALIDATION_RESULTS }}\").add_html(\n                \"METRIC_VALIDATION_RESULTS\",\n                \"<h3 class='section-title'>Model Validation Results (Test Dataset)</h3> \"\n                + criteria_html,\n            )\n\n        if self.recipe == \"classification/v1\":\n            classifiers_plot_tab = card.add_tab(\n                \"Model Performance Plots\",\n                \"{{ CONFUSION_MATRIX }} {{CONFUSION_MATRIX_PLOT}}\"\n                + \"{{ LIFT_CURVE }} {{LIFT_CURVE_PLOT}}\"\n                + \"{{ PR_CURVE }} {{PR_CURVE_PLOT}}\"\n                + \"{{ ROC_CURVE }} {{ROC_CURVE_PLOT}}\",\n            )\n            confusion_matrix_path = os.path.join(\n                output_directory,\n                \"eval_validation/artifacts\",\n                f\"{_VALIDATION_METRIC_PREFIX}confusion_matrix.png\",\n            )\n            if os.path.exists(confusion_matrix_path):\n                classifiers_plot_tab.add_html(\n                    \"CONFUSION_MATRIX\",\n                    '<h3 class=\"section-title\">Confusion Matrix Plot</h3>',\n                )\n                classifiers_plot_tab.add_image(\n                    \"CONFUSION_MATRIX_PLOT\", confusion_matrix_path, width=400\n                )\n\n            lift_curve_path = os.path.join(\n                output_directory,\n                \"eval_validation/artifacts\",\n                f\"{_VALIDATION_METRIC_PREFIX}lift_curve_plot.png\",\n            )\n            if os.path.exists(lift_curve_path):\n                classifiers_plot_tab.add_html(\n                    \"LIFT_CURVE\",\n                    '<h3 class=\"section-title\">Lift Curve Plot</h3>',\n                )\n                classifiers_plot_tab.add_image(\"LIFT_CURVE_PLOT\", lift_curve_path, width=400)\n\n            pr_curve_path = os.path.join(\n                output_directory,\n                \"eval_validation/artifacts\",\n                f\"{_VALIDATION_METRIC_PREFIX}precision_recall_curve_plot.png\",\n            )\n            if os.path.exists(pr_curve_path):\n                classifiers_plot_tab.add_html(\n                    \"PR_CURVE\",\n                    '<h3 class=\"section-title\">Precision Recall Curve Plot</h3>',\n                )\n                classifiers_plot_tab.add_image(\"PR_CURVE_PLOT\", pr_curve_path, width=400)\n\n            roc_curve_path = os.path.join(\n                output_directory,\n                \"eval_validation/artifacts\",\n                f\"{_VALIDATION_METRIC_PREFIX}roc_curve_plot.png\",\n            )\n            if os.path.exists(roc_curve_path):\n                classifiers_plot_tab.add_html(\n                    \"ROC_CURVE\",\n                    '<h3 class=\"section-title\">ROC Curve Plot</h3>',\n                )\n                classifiers_plot_tab.add_image(\"ROC_CURVE_PLOT\", roc_curve_path, width=400)\n\n        def _add_shap_plots(card):\n            \n            shap_plot_tab = card.add_tab(\n                \"Feature Importance\",\n                '<h3 class=\"section-title\">Feature Importance on Validation Dataset</h3>'\n                '<h3 class=\"section-title\">SHAP Bar Plot</h3>{{SHAP_BAR_PLOT}}'\n                '<h3 class=\"section-title\">SHAP Beeswarm Plot</h3>{{SHAP_BEESWARM_PLOT}}',\n            )\n\n            shap_bar_plot_path = os.path.join(\n                output_directory,\n                \"eval_validation/artifacts\",\n                f\"{_VALIDATION_METRIC_PREFIX}shap_feature_importance_plot.png\",\n            )\n            shap_beeswarm_plot_path = os.path.join(\n                output_directory,\n                \"eval_validation/artifacts\",\n                f\"{_VALIDATION_METRIC_PREFIX}shap_beeswarm_plot.png\",\n            )\n            shap_plot_tab.add_image(\"SHAP_BAR_PLOT\", shap_bar_plot_path, width=800)\n            shap_plot_tab.add_image(\"SHAP_BEESWARM_PLOT\", shap_beeswarm_plot_path, width=800)\n\n        try:\n            import shap\n            from matplotlib import pyplot\n\n            _add_shap_plots(card)\n        except ImportError:\n            _logger.warning(\n                \"SHAP or matplotlib package is not installed, so shap plots will not be added.\"\n            )\n\n        warning_output_path = os.path.join(output_directory, \"warning_logs.txt\")\n        if os.path.exists(warning_output_path):\n            warnings_output_tab = card.add_tab(\"Warning Logs\", \"{{ STEP_WARNINGS }}\")\n            with open(warning_output_path) as f:\n                warnings_output_tab.add_html(\"STEP_WARNINGS\", f\"<pre>{f.read()}</pre>\")\n\n        run_summary_card_tab = card.add_tab(\n            \"Run Summary\",\n            \"{{ RUN_ID }} \"\n            + \"{{ MODEL_URI }}\"\n            + \"{{ VALIDATION_STATUS }}\"\n            + \"{{ EXE_DURATION }}\"\n            + \"{{ LAST_UPDATE_TIME }}\",\n        ).add_markdown(\n            \"VALIDATION_STATUS\", f\"**Validation status:** `{self.model_validation_status}`\"\n        )\n        run_url = get_databricks_run_url(\n            tracking_uri=mlflow.get_tracking_uri(),\n            run_id=run_id,\n        )\n        model_uri = f\"runs:/{run_id}/train/{TrainStep.MODEL_ARTIFACT_RELATIVE_PATH}\"\n        model_url = get_databricks_run_url(\n            tracking_uri=mlflow.get_tracking_uri(),\n            run_id=run_id,\n            artifact_path=f\"train/{TrainStep.MODEL_ARTIFACT_RELATIVE_PATH}\",\n        )\n\n        if run_url is not None:\n            run_summary_card_tab.add_html(\n                \"RUN_ID\", f\"<b>MLflow Run ID:</b> <a href={run_url}>{run_id}</a><br><br>\"\n            )\n        else:\n            run_summary_card_tab.add_markdown(\"RUN_ID\", f\"**MLflow Run ID:** `{run_id}`\")\n\n        if model_url is not None:\n            run_summary_card_tab.add_html(\n                \"MODEL_URI\", f\"<b>MLflow Model URI:</b> <a href={model_url}>{model_uri}</a>\"\n            )\n        else:\n            run_summary_card_tab.add_markdown(\"MODEL_URI\", f\"**MLflow Model URI:** `{model_uri}`\")\n\n        return card\n"
    },
    {
      "id": "mlflow_mlflow_3377_7",
      "input_code": "    def _build_card(self, run_id: str) -> BaseCard:\n        card = BaseCard(self.recipe_name, self.name)\n        card_tab = card.add_tab(\n            \"Run Summary\",\n            \"{{ MODEL_NAME }}\"\n            + \"{{ MODEL_VERSION }}\"\n            + \"{{ MODEL_SOURCE_URI }}\"\n            + \"{{ ALERTS }}\"\n            + \"{{ EXE_DURATION }}\"\n            + \"{{ LAST_UPDATE_TIME }}\",\n        )\n\n        if self.version is not None:\n            model_version_url = get_databricks_model_version_url(\n                registry_uri=mlflow.get_registry_uri(),\n                name=self.register_model_name,\n                version=self.version,\n            )\n\n            if model_version_url is not None:\n                card_tab.add_html(\n                    \"MODEL_NAME\",\n                    (\n                        f\"<b>Model Name:</b> <a href={model_version_url}>\"\n                        f\"{self.register_model_name}</a><br><br>\"\n                    ),\n                )\n                card_tab.add_html(\n                    \"MODEL_VERSION\",\n                    (\n                        f\"<b>Model Version</b> <a href={model_version_url}>\"\n                        f\"{self.version}</a><br><br>\"\n                    ),\n                )\n            else:\n                card_tab.add_markdown(\n                    \"MODEL_NAME\",\n                    f\"**Model Name:** `{self.register_model_name}`\",\n                )\n                card_tab.add_markdown(\n                    \"MODEL_VERSION\",\n                    f\"**Model Version:** `{self.version}`\",\n                )\n\n        model_source_url = get_databricks_run_url(\n            tracking_uri=mlflow.get_tracking_uri(),\n            run_id=run_id,\n            artifact_path=f\"train/{TrainStep.MODEL_ARTIFACT_RELATIVE_PATH}\",\n        )\n\n        if self.model_uri is not None and model_source_url is not None:\n            card_tab.add_html(\n                \"MODEL_SOURCE_URI\",\n                f\"<b>Model Source URI</b> <a href={model_source_url}>{self.model_uri}</a>\",\n            )\n        elif self.model_uri is not None:\n            card_tab.add_markdown(\n                \"MODEL_SOURCE_URI\",\n                f\"**Model Source URI:** `{self.model_uri}`\",\n            )\n\n        return card\n"
    },
    {
      "id": "mlflow_mlflow_3377_2",
      "input_code": "    def add_image(\n        self,\n        name: str,\n        image_file_path: str,\n        width: Optional[int] = None,\n        height: Optional[int] = None,\n    ) -> None:\n        if not os.path.exists(image_file_path):\n            self.add_html(name, \"Image Unavailable\")\n            _logger.warning(f\"Unable to locate image file {image_file_path} to render {name}.\")\n            return\n\n        with open(image_file_path, \"rb\") as f:\n            base64_str = base64.b64encode(f.read()).decode(\"utf-8\")\n\n        image_type = pathlib.Path(image_file_path).suffix[1:]\n\n        width_style = f'width=\"{width}\"' if width else \"\"\n        height_style = f'height=\"{width}\"' if height else \"\"\n        img_html = (\n            f'<img src=\"data:image/{image_type};base64, {base64_str}\" '\n            f\"{width_style} {height_style} />\"\n        )\n        self.add_html(name, img_html)\n"
    },
    {
      "id": "mlflow_mlflow_3377_5",
      "input_code": "    def _build_step_card(        self,\n        ingested_dataset_profile: str,\n        ingested_rows: int,\n        schema: dict,\n        data_preview: pd.DataFrame = None,\n        dataset_src_location: Optional[str] = None,\n        dataset_sql: Optional[str] = None,\n    ) -> BaseCard:\n        \n        if dataset_src_location is None and dataset_sql is None:\n            raise MlflowException(\n                message=(\n                    \"Failed to build step card because neither a dataset location nor a\"\n                    \" dataset Spark SQL query were specified\"\n                ),\n                error_code=INVALID_PARAMETER_VALUE,\n            )\n\n        card = BaseCard(self.recipe_name, self.name)\n        if not self.skip_data_profiling:\n            (                card.add_tab(\"Data Profile\", \"{{PROFILE}}\").add_pandas_profile(\n                    \"PROFILE\", ingested_dataset_profile\n                )\n            )\n        schema_html = BaseCard.render_table(schema[\"fields\"])\n        card.add_tab(\"Data Schema\", \"{{SCHEMA}}\").add_html(\"SCHEMA\", schema_html)\n\n        if data_preview is not None:\n            card.add_tab(\"Data Preview\", \"{{DATA_PREVIEW}}\").add_html(\n                \"DATA_PREVIEW\", BaseCard.render_table(data_preview)\n            )\n\n        (            card.add_tab(\n                \"Run Summary\",\n                \"{{ INGESTED_ROWS }}\"\n                + \"{{ DATA_SOURCE }}\"\n                + \"{{ EXE_DURATION }}\"\n                + \"{{ LAST_UPDATE_TIME }}\",\n            )\n            .add_markdown(\n                name=\"INGESTED_ROWS\",\n                markdown=f\"**Number of rows ingested:** `{ingested_rows}`\",\n            )\n            .add_markdown(\n                name=\"DATA_SOURCE\",\n                markdown=(\n                    f\"**Dataset source location:** `{dataset_src_location}`\"\n                    if dataset_src_location is not None\n                    else f\"**Dataset SQL:** `{dataset_sql}`\"\n                ),\n            )\n        )\n        return card\n"
    },
    {
      "id": "mlflow_mlflow_3377_11",
      "input_code": "def test_card_tab_works():\n    profile_report = \"pandas-profiling\"\n    tab = (\n        CardTab(\"tab\", \"{{MARKDOWN_1}}{{HTML_1}}{{PROFILE_1}}\")\n        .add_html(\"HTML_1\", \"<span style='color:blue'>blue</span>\")\n        .add_markdown(\"MARKDOWN_1\", \"#### Hello, world!\")\n        .add_pandas_profile(\"PROFILE_1\", profile_report)\n    )\n    assert (\n        tab.to_html()\n        == \"<h4>Hello, world!</h4><span style='color:blue'>blue</span>\"\n        + \"<iframe srcdoc='pandas-profiling' width='100%' height='500' frameborder='0'></iframe>\"\n    )\n"
    },
    {
      "id": "mlflow_mlflow_3377_9",
      "input_code": "    def _build_profiles_and_card(self, train_df, train_transformed, transformer) -> BaseCard:\n        card = BaseCard(self.recipe_name, self.name)\n\n        if not self.skip_data_profiling:\n            train_transformed_profile = get_pandas_data_profiles(\n                [[\"Profile of Train Transformed Dataset\", train_transformed]]\n            )\n            card.add_tab(\"Data Profile (Train Transformed)\", \"{{PROFILE}}\").add_pandas_profile(\n                \"PROFILE\", train_transformed_profile\n            )\n\n        from sklearn import set_config\n        from sklearn.utils import estimator_html_repr\n\n        set_config(display=\"diagram\")\n        transformer_repr = estimator_html_repr(transformer)\n        card.add_tab(\"Transformer\", \"{{TRANSFORMER}}\").add_html(\"TRANSFORMER\", transformer_repr)\n\n        card.add_tab(\"Input Schema\", \"{{INPUT_SCHEMA}}\").add_html(\n            \"INPUT_SCHEMA\",\n            BaseCard.render_table({\"Name\": n, \"Type\": t} for n, t in train_df.dtypes.items()),\n        )\n\n        try:\n            card.add_tab(\"Output Schema\", \"{{OUTPUT_SCHEMA}}\").add_html(\n                \"OUTPUT_SCHEMA\",\n                BaseCard.render_table(\n                    {\"Name\": n, \"Type\": t} for n, t in train_transformed.dtypes.items()\n                ),\n            )\n        except Exception as e:\n            card.add_tab(\"Output Schema\", \"{{OUTPUT_SCHEMA}}\").add_html(\n                \"OUTPUT_SCHEMA\", f\"Failed to extract transformer schema. Error: {e}\"\n            )\n\n        card.add_tab(\"Data Preview\", \"{{DATA_PREVIEW}}\").add_html(\n            \"DATA_PREVIEW\", BaseCard.render_table(train_transformed.head())\n        )\n\n        (\n            card.add_tab(\n                \"Run Summary\",\n                \"\"\"\n                {{ EXE_DURATION }}\n                {{ LAST_UPDATE_TIME }}\n                \"\"\",\n            )\n        )\n\n        return card\n"
    },
    {
      "id": "mlflow_mlflow_3377_3",
      "input_code": "    def add_pandas_profile(self, name: str, profile: str) -> CardTab:\n        \n        try:\n            profile_iframe = (\n                \"<iframe srcdoc='{src}' width='100%' height='500' frameborder='0'></iframe>\"\n            ).format(src=html.escape(profile))\n        except Exception as e:\n            profile_iframe = f\"Unable to create data profile. Error found:\\n{e}\"\n        self.add_html(name, profile_iframe)\n        return self\n"
    },
    {
      "id": "mlflow_mlflow_3377_1",
      "input_code": "    def add_markdown(self, name: str, markdown: str) -> CardTab:\n        \n        from markdown import markdown as md_to_html\n\n        self.add_html(name, md_to_html(markdown))\n        return self\n"
    },
    {
      "id": "mlflow_mlflow_3377_8",
      "input_code": "    def _build_step_card(\n        self,\n        eval_metrics,\n        pred_and_error_df,\n        model_schema,\n        run_id,\n        model_uri,\n        worst_examples_df,\n        train_df,\n        output_directory,\n        leaderboard_df=None,\n        tuning_df=None,\n        calibrated_plot=None,\n    ):\n        import pandas as pd\n        from sklearn import set_config\n        from sklearn.utils import estimator_html_repr\n\n        card = BaseCard(self.recipe_name, self.name)\n        metric_df = (\n            get_merged_eval_metrics(\n                eval_metrics,\n                ordered_metric_names=[\n                    self.primary_metric,\n                    *self.user_defined_custom_metrics.keys(),\n                ],\n            )\n            .reset_index()\n            .rename(columns={\"index\": \"Metric\"})\n        )\n\n        def row_style(row):\n            if row.Metric == self.primary_metric or row.Metric in self.user_defined_custom_metrics:\n                return pd.Series(\"font-weight: bold\", row.index)\n            else:\n                return pd.Series(\"\", row.index)\n\n        metric_table_html = BaseCard.render_table(\n            metric_df.style.format({\"training\": \"{:.6g}\", \"validation\": \"{:.6g}\"}).apply(\n                row_style, axis=1\n            )\n        )\n\n        card.add_tab(\n            \"Model Performance\",\n            \"<h3 class='section-title'>Summary Metrics (Validation)</h3>{{ METRICS }} \",\n        ).add_html(\"METRICS\", metric_table_html)\n\n        if not self.skip_data_profiling:\n            pred_and_error_df_profile = get_pandas_data_profiles(\n                [\n                    [\n                        \"Predictions and Errors (Validation Dataset)\",\n                        pred_and_error_df.reset_index(drop=True),\n                    ]\n                ]\n            )\n            card.add_tab(\"Data Profile (Predictions)\", \"{{PROFILE}}\").add_pandas_profile(\n                \"PROFILE\", pred_and_error_df_profile\n            )\n        set_config(display=\"diagram\")\n        model_repr = estimator_html_repr(\n            mlflow.sklearn.load_model(\n                os.path.join(model_uri, \"artifacts\", TrainStep.SKLEARN_MODEL_ARTIFACT_RELATIVE_PATH)\n            )\n        )\n        card.add_tab(\"Model Architecture\", \"{{MODEL_ARCH}}\").add_html(\"MODEL_ARCH\", model_repr)\n\n        def render_schema(inputs, title):\n            from mlflow.types import ColSpec\n\n            table = BaseCard.render_table(\n                {\n                    \"Name\": \"  \" + (spec.name or \"-\"),\n                    \"Type\": repr(spec.type) if isinstance(spec, ColSpec) else repr(spec),\n                }\n                for spec in inputs\n            )\n            return f'<div style=\"margin: 5px\"><h2>{title}</h2>{table}</div>'\n\n        schema_tables = [render_schema(model_schema.inputs.inputs, \"Inputs\")]\n        if model_schema.outputs:\n            schema_tables += [render_schema(model_schema.outputs.inputs, \"Outputs\")]\n\n        card.add_tab(\"Model Schema\", \"{{MODEL_SCHEMA}}\").add_html(\n            \"MODEL_SCHEMA\",\n            '<div style=\"display: flex\">{tables}</div>'.format(tables=\"\\n\".join(schema_tables)),\n        )\n\n        if not worst_examples_df.empty:\n            (\n                card.add_tab(\"Worst Predictions\", \"{{ WORST_EXAMPLES_TABLE }}\").add_html(\n                    \"WORST_EXAMPLES_TABLE\", BaseCard.render_table(worst_examples_df)\n                )\n            )\n\n        if calibrated_plot:\n            calibrated_plot_location = os.path.join(output_directory, \"calibrated_plot_location\")\n            calibrated_plot.figure_.savefig(calibrated_plot_location, format=\"png\")\n            (\n                card.add_tab(\"Prob. Calibration\", \"{{ CALIBRATED_PLOT }}\").add_image(\n                    \"CALIBRATED_PLOT\", calibrated_plot_location\n                )\n            )\n\n        if not self.skip_data_profiling:\n            worst_prediction_profile = get_pandas_data_profiles(\n                [\n                    [\"Worst Predictions\", worst_examples_df.reset_index(drop=True)],\n                    [\"Train\", train_df.reset_index(drop=True)],\n                ]\n            )\n            card.add_tab(\n                \"Data Profile (Worst vs Train)\", \"{{ WORST_EXAMPLES_COMP }}\"\n            ).add_pandas_profile(\"WORST_EXAMPLES_COMP\", worst_prediction_profile)\n\n        if leaderboard_df is not None:\n            (\n                card.add_tab(\"Leaderboard\", \"{{ LEADERBOARD_TABLE }}\").add_html(\n                    \"LEADERBOARD_TABLE\", BaseCard.render_table(leaderboard_df, hide_index=False)\n                )\n            )\n\n        is_automl_run = self.step_config[\"using\"].startswith(\"automl\")\n        best_parameters_yaml = os.path.join(output_directory, \"best_parameters.yaml\")\n\n        if os.path.exists(best_parameters_yaml):\n            best_parameters_card_tab = card.add_tab(\n                f\"Best Parameters {' (AutoML)' if is_automl_run else ''}\",\n                \"{{ BEST_PARAMETERS }} \",\n            )\n\n            if is_automl_run:\n                automl_estimator_str = (\n                    f\"<b>Best estimator:</b><br>\"\n                    f\"<pre>{self.best_estimator_name}</pre><br>\"\n                    f\"<b>Best estimator class:</b><br>\"\n                    f\"<pre>{self.best_estimator_class}</pre><br><br>\"\n                )\n            else:\n                automl_estimator_str = \"\"\n\n            with open(best_parameters_yaml) as f:\n                best_parameters = f.read()\n            best_parameters_card_tab.add_html(\n                \"BEST_PARAMETERS\",\n                f\"{automl_estimator_str}<b>Best parameters:</b><br>\"\n                f\"<pre>{best_parameters}</pre><br><br>\",\n            )\n\n        if tuning_df is not None:\n            tuning_trials_card_tab = card.add_tab(\n                \"Tuning Trials\",\n                \"{{ SEARCH_SPACE }}\" + \"{{ TUNING_TABLE_TITLE }}\" + \"{{ TUNING_TABLE }}\",\n            )\n            tuning_params = yaml.dump(self.step_config[\"tuning\"][\"parameters\"])\n            tuning_trials_card_tab.add_html(\n                \"SEARCH_SPACE\",\n                f\"<b>Tuning search space:</b> <br><pre>{tuning_params}</pre><br><br>\",\n            )\n            tuning_trials_card_tab.add_html(\"TUNING_TABLE_TITLE\", \"<b>Tuning results:</b><br>\")\n            tuning_trials_card_tab.add_html(\n                \"TUNING_TABLE\",\n                BaseCard.render_table(\n                    tuning_df.style.apply(\n                        lambda row: pd.Series(\"font-weight: bold\", row.index),\n                        axis=1,\n                        subset=tuning_df.index[0],\n                    ),\n                    hide_index=True,\n                ),\n            )\n\n        warning_output_path = os.path.join(output_directory, \"warning_logs.txt\")\n        if os.path.exists(warning_output_path):\n            warnings_output_tab = card.add_tab(\"Warning Logs\", \"{{ STEP_WARNINGS }}\")\n            with open(warning_output_path) as f:\n                warnings_output_tab.add_html(\"STEP_WARNINGS\", f\"<pre>{f.read()}</pre>\")\n\n        run_card_tab = card.add_tab(\n            \"Run Summary\",\n            \"{{ RUN_ID }} \" + \"{{ MODEL_URI }}\" + \"{{ EXE_DURATION }}\" + \"{{ LAST_UPDATE_TIME }}\",\n        )\n        model_uri_path = f\"runs:/{run_id}/train/model\"\n        run_url = get_databricks_run_url(\n            tracking_uri=mlflow.get_tracking_uri(),\n            run_id=run_id,\n        )\n        model_url = get_databricks_run_url(\n            tracking_uri=mlflow.get_tracking_uri(),\n            run_id=run_id,\n            artifact_path=re.sub(rf\"^.*?{run_id}\", \"\", model_uri_path),\n        )\n\n        if run_url is not None:\n            run_card_tab.add_html(\n                \"RUN_ID\", f\"<b>MLflow Run ID:</b> <a href={run_url}>{run_id}</a><br><br>\"\n            )\n        else:\n            run_card_tab.add_markdown(\"RUN_ID\", f\"**MLflow Run ID:** `{run_id}`\")\n\n        if model_url is not None:\n            run_card_tab.add_html(\n                \"MODEL_URI\", f\"<b>MLflow Model URI:</b> <a href={model_url}>{model_uri_path}</a>\"\n            )\n        else:\n            run_card_tab.add_markdown(\"MODEL_URI\", f\"**MLflow Model URI:** `{model_uri_path}`\")\n\n        return card\n"
    },
    {
      "id": "mlflow_mlflow_3377_4",
      "input_code": "    def __init__(\n        self, recipe_name: str, step_name: str, failure_traceback: str, output_directory: str\n    ):\n        super().__init__(\n            recipe_name=recipe_name,\n            step_name=step_name,\n        )\n        self.add_tab(\"Step Status\", \"{{ STEP_STATUS }}\").add_html(\n            \"STEP_STATUS\",\n            '<p><strong>Step status: <span style=\"color:red\">Failed</span></strong></p>',\n        )\n        self.add_tab(\n            \"Stacktrace\",\n            (\n                \"<div class='stacktrace-container'><p style='margin-top:0px'><code>\"\n                \"{{ STACKTRACE|e }}</code></p></div>\"\n            ),\n        ).add_html(\"STACKTRACE\", str(failure_traceback))\n        warning_output_path = os.path.join(output_directory, \"warning_logs.txt\")\n        if os.path.exists(warning_output_path):\n            with open(warning_output_path) as f:\n                self.add_tab(\"Warning Logs\", \"{{ STEP_WARNINGS }}\").add_html(\n                    \"STEP_WARNINGS\", f\"<pre>{f.read()}</pre>\"\n                )\n"
    }
  ],
  "generated_inputs": [
    "```python\n<needimport>\nimport mlflow\n\n<testcase_1>\nname = \"HTML_1\"\nhtml_content = \"<div><p>This is a test paragraph.</p></div>\"\n\n<testcase_2>\nname = \"SUMMARY\"\nhtml_content = \"<h1>Summary Report</h1><p>Details of the report go here.</p>\"\n\n<testcase_3>\nname = \"PROFILE\"\nhtml_content = \"<iframe srcdoc='profile-content' width='100%' height='500' frameborder='0'></iframe>\"\n\n<testcase_4>\nname = \"MODEL_URI\"\nhtml_content = \"<a href='http://example.com/model'>Model Link</a>\"\n\n<testcase_5>\nname = \"DATA_PREVIEW\"\nhtml_content = \"<table><tr><td>Data 1</td></tr><tr><td>Data 2</td></tr></table>\"\n```"
  ],
  "gpt_output": "```python\n<needimport>\nimport mlflow\n\n<testcase_1>\nname = \"HTML_1\"\nhtml_content = \"<div><p>This is a test paragraph.</p></div>\"\n\n<testcase_2>\nname = \"SUMMARY\"\nhtml_content = \"<h1>Summary Report</h1><p>Details of the report go here.</p>\"\n\n<testcase_3>\nname = \"PROFILE\"\nhtml_content = \"<iframe srcdoc='profile-content' width='100%' height='500' frameborder='0'></iframe>\"\n\n<testcase_4>\nname = \"MODEL_URI\"\nhtml_content = \"<a href='http://example.com/model'>Model Link</a>\"\n\n<testcase_5>\nname = \"DATA_PREVIEW\"\nhtml_content = \"<table><tr><td>Data 1</td></tr><tr><td>Data 2</td></tr></table>\"\n```",
  "needimport": "import mlflow\n\n",
  "test_results": {
    "ans1": "Dummy(template=default_template, _variables={'HTML_1': 'valid_variable', 'SUMMARY': 'valid_variable', 'PROFILE': 'valid_variable', 'MODEL_URI': 'valid_variable', 'DATA_PREVIEW': 'valid_variable'}, _context={'HTML_1': '<div><p>This is a test paragraph.</p></div>'})",
    "ans2": "Dummy(template=default_template, _variables={'HTML_1': 'valid_variable', 'SUMMARY': 'valid_variable', 'PROFILE': 'valid_variable', 'MODEL_URI': 'valid_variable', 'DATA_PREVIEW': 'valid_variable'}, _context={'SUMMARY': '<h1>Summary Report</h1><p>Details of the report go here.</p>'})",
    "ans3": "Dummy(template=default_template, _variables={'HTML_1': 'valid_variable', 'SUMMARY': 'valid_variable', 'PROFILE': 'valid_variable', 'MODEL_URI': 'valid_variable', 'DATA_PREVIEW': 'valid_variable'}, _context={'PROFILE': \"<iframe srcdoc='profile-content' width='100%' height='500' frameborder='0'></iframe>\"})",
    "ans4": "Dummy(template=default_template, _variables={'HTML_1': 'valid_variable', 'SUMMARY': 'valid_variable', 'PROFILE': 'valid_variable', 'MODEL_URI': 'valid_variable', 'DATA_PREVIEW': 'valid_variable'}, _context={'MODEL_URI': \"<a href='http://example.com/model'>Model Link</a>\"})",
    "ans5": "Dummy(template=default_template, _variables={'HTML_1': 'valid_variable', 'SUMMARY': 'valid_variable', 'PROFILE': 'valid_variable', 'MODEL_URI': 'valid_variable', 'DATA_PREVIEW': 'valid_variable'}, _context={'DATA_PREVIEW': '<table><tr><td>Data 1</td></tr><tr><td>Data 2</td></tr></table>'})"
  }
}