{
  "input_header": "def step_did_not_run(logs, step_key):",
  "input_docstring": null,
  "output_code": "def step_did_not_run(logs, step_key):\n    return not any(\n        log[\"stepKey\"] == step_key\n        for log in logs\n        if log[\"__typename\"]\n        in (\"ExecutionStepSuccessEvent\", \"ExecutionStepSkippedEvent\", \"ExecutionStepFailureEvent\")\n    )",
  "input_contexts": [
    {
      "id": "dagster-io_dagster_5585_2",
      "input_code": "def test_dynamic_subset(graphql_context: WorkspaceRequestContext):\n    selector = infer_job_selector(graphql_context, \"dynamic_job\")\n    result = execute_dagster_graphql_and_finish_runs(\n        graphql_context,\n        LAUNCH_PIPELINE_EXECUTION_MUTATION,\n        variables={\n            \"executionParams\": {\n                \"selector\": selector,\n                \"runConfigData\": {\n                    \"ops\": {\"multiply_inputs\": {\"inputs\": {\"should_fail\": {\"value\": True}}}},\n                },\n            }\n        },\n    )\n\n    assert not result.errors\n    assert result.data\n    assert result.data[\"launchPipelineExecution\"][\"__typename\"] == \"LaunchRunSuccess\"\n    assert result.data[\"launchPipelineExecution\"][\"run\"][\"pipeline\"][\"name\"] == \"dynamic_job\"\n\n    parent_run_id = result.data[\"launchPipelineExecution\"][\"run\"][\"runId\"]\n\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)[\n        \"pipelineRunLogs\"\n    ][\"messages\"]\n\n    assert step_did_succeed(logs, \"emit\")\n    assert step_did_succeed(logs, \"multiply_inputs[0]\")\n    assert step_did_succeed(logs, \"multiply_inputs[1]\")\n    assert step_did_fail(logs, \"multiply_inputs[2]\")\n    assert step_did_succeed(logs, \"multiply_by_two[0]\")\n    assert step_did_succeed(logs, \"multiply_by_two[1]\")\n\n    retry_one = execute_dagster_graphql_and_finish_runs(\n        graphql_context,\n        LAUNCH_PIPELINE_REEXECUTION_MUTATION,\n        variables={\n            \"executionParams\": {\n                \"selector\": selector,\n                \"runConfigData\": {\n                    \"ops\": {\"multiply_inputs\": {\"inputs\": {\"should_fail\": {\"value\": True}}}},\n                },\n                \"executionMetadata\": {\n                    \"rootRunId\": parent_run_id,\n                    \"parentRunId\": parent_run_id,\n                },\n                \"stepKeys\": [\n                    \"multiply_inputs[2]\",\n                    \"multiply_by_two[2]\",\n                    \"sum_numbers\",\n                    \"double_total\",\n                ],\n            }\n        },\n    )\n    assert not retry_one.errors\n    assert retry_one.data\n    assert (\n        retry_one.data[\"launchPipelineReexecution\"][\"__typename\"] == \"LaunchRunSuccess\"\n    ), retry_one.data[\"launchPipelineReexecution\"].get(\"message\")\n\n    run_id = retry_one.data[\"launchPipelineReexecution\"][\"run\"][\"runId\"]\n\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)[\n        \"pipelineRunLogs\"\n    ][\"messages\"]\n\n    assert step_did_not_run(logs, \"emit\")\n    assert step_did_not_run(logs, \"multiply_inputs[0]\")\n    assert step_did_not_run(logs, \"multiply_inputs[1]\")\n    assert step_did_succeed(logs, \"multiply_inputs[2]\")\n\n    assert step_did_not_run(logs, \"multiply_by_two[0]\")\n    assert step_did_not_run(logs, \"multiply_by_two[1]\")\n    assert step_did_succeed(logs, \"multiply_by_two[2]\")\n    assert step_did_succeed(logs, \"double_total\")\n"
    },
    {
      "id": "dagster-io_dagster_5585_6",
      "input_code": "    def test_retry_resource_pipeline(self, graphql_context: WorkspaceRequestContext):\n        context = graphql_context\n        selector = infer_job_selector(graphql_context, \"retry_resource_job\")\n        result = execute_dagster_graphql_and_finish_runs(\n            context,\n            LAUNCH_PIPELINE_EXECUTION_MUTATION,\n            variables={\n                \"executionParams\": {\n                    \"selector\": selector,\n                }\n            },\n        )\n\n        run_id = result.data[\"launchPipelineExecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(context, run_id)[\"pipelineRunLogs\"][\n            \"messages\"\n        ]\n        assert step_did_succeed(logs, \"start\")\n        assert step_did_fail(logs, \"will_fail\")\n\n        retry_one = execute_dagster_graphql_and_finish_runs(\n            context,\n            LAUNCH_PIPELINE_REEXECUTION_MUTATION,\n            variables={\n                \"executionParams\": {\n                    \"selector\": selector,\n                    \"executionMetadata\": {\n                        \"rootRunId\": run_id,\n                        \"parentRunId\": run_id,\n                        \"tags\": [{\"key\": RESUME_RETRY_TAG, \"value\": \"true\"}],\n                    },\n                }\n            },\n        )\n        run_id = retry_one.data[\"launchPipelineReexecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(context, run_id)[\"pipelineRunLogs\"][\n            \"messages\"\n        ]\n        assert step_did_not_run(logs, \"start\")\n        assert step_did_fail(logs, \"will_fail\")\n"
    },
    {
      "id": "dagster-io_dagster_5585_1",
      "input_code": "def test_dynamic_resume_reexecution(graphql_context: WorkspaceRequestContext):\n    selector = infer_job_selector(graphql_context, \"dynamic_job\")\n    result = execute_dagster_graphql_and_finish_runs(\n        graphql_context,\n        LAUNCH_PIPELINE_EXECUTION_MUTATION,\n        variables={\n            \"executionParams\": {\n                \"selector\": selector,\n                \"runConfigData\": {\n                    \"ops\": {\"multiply_inputs\": {\"inputs\": {\"should_fail\": {\"value\": True}}}},\n                },\n            }\n        },\n    )\n\n    assert not result.errors\n    assert result.data\n    assert result.data[\"launchPipelineExecution\"][\"__typename\"] == \"LaunchRunSuccess\"\n    assert result.data[\"launchPipelineExecution\"][\"run\"][\"pipeline\"][\"name\"] == \"dynamic_job\"\n\n    parent_run_id = result.data[\"launchPipelineExecution\"][\"run\"][\"runId\"]\n\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)[\n        \"pipelineRunLogs\"\n    ][\"messages\"]\n\n    assert step_did_succeed(logs, \"emit\")\n    assert step_did_succeed(logs, \"multiply_inputs[0]\")\n    assert step_did_succeed(logs, \"multiply_inputs[1]\")\n    assert step_did_fail(logs, \"multiply_inputs[2]\")\n    assert step_did_succeed(logs, \"multiply_by_two[0]\")\n    assert step_did_succeed(logs, \"multiply_by_two[1]\")\n\n    retry_one = execute_dagster_graphql_and_finish_runs(\n        graphql_context,\n        LAUNCH_PIPELINE_REEXECUTION_MUTATION,\n        variables={\n            \"executionParams\": {\n                \"selector\": selector,\n                \"runConfigData\": {\n                    \"ops\": {\"multiply_inputs\": {\"inputs\": {\"should_fail\": {\"value\": True}}}},\n                },\n                \"executionMetadata\": {\n                    \"rootRunId\": parent_run_id,\n                    \"parentRunId\": parent_run_id,\n                    \"tags\": [{\"key\": RESUME_RETRY_TAG, \"value\": \"true\"}],\n                },\n            }\n        },\n    )\n    assert not retry_one.errors\n    assert retry_one.data\n    assert (\n        retry_one.data[\"launchPipelineReexecution\"][\"__typename\"] == \"LaunchRunSuccess\"\n    ), retry_one.data[\"launchPipelineReexecution\"].get(\"message\")\n\n    run_id = retry_one.data[\"launchPipelineReexecution\"][\"run\"][\"runId\"]\n\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)[\n        \"pipelineRunLogs\"\n    ][\"messages\"]\n\n    assert step_did_not_run(logs, \"emit\")\n    assert step_did_not_run(logs, \"multiply_inputs[0]\")\n    assert step_did_not_run(logs, \"multiply_inputs[1]\")\n    assert step_did_succeed(logs, \"multiply_inputs[2]\")\n\n    assert step_did_not_run(logs, \"multiply_by_two[0]\")\n    assert step_did_not_run(logs, \"multiply_by_two[1]\")\n    assert step_did_succeed(logs, \"multiply_by_two[2]\")\n    assert step_did_succeed(logs, \"double_total\")\n"
    },
    {
      "id": "dagster-io_dagster_5585_5",
      "input_code": "    def test_retry_pipeline_execution(self, graphql_context: WorkspaceRequestContext):\n        selector = infer_job_selector(graphql_context, \"eventually_successful\")\n        result = execute_dagster_graphql_and_finish_runs(\n            graphql_context,\n            LAUNCH_PIPELINE_EXECUTION_MUTATION,\n            variables={\n                \"executionParams\": {\n                    \"selector\": selector,\n                    \"runConfigData\": retry_config(0),\n                }\n            },\n        )\n\n        run_id = result.data[\"launchPipelineExecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)[\n            \"pipelineRunLogs\"\n        ][\"messages\"]\n\n        assert step_did_succeed(logs, \"spawn\")\n        assert step_did_fail(logs, \"fail\")\n        assert step_did_not_run(logs, \"fail_2\")\n        assert step_did_not_run(logs, \"fail_3\")\n        assert step_did_not_run(logs, \"reset\")\n        assert step_did_not_run(logs, \"collect\")\n\n        retry_one = execute_dagster_graphql_and_finish_runs(\n            graphql_context,\n            LAUNCH_PIPELINE_REEXECUTION_MUTATION,\n            variables={\n                \"executionParams\": {\n                    \"selector\": selector,\n                    \"runConfigData\": retry_config(1),\n                    \"executionMetadata\": {\n                        \"rootRunId\": run_id,\n                        \"parentRunId\": run_id,\n                        \"tags\": [{\"key\": RESUME_RETRY_TAG, \"value\": \"true\"}],\n                    },\n                }\n            },\n        )\n\n        run_id = retry_one.data[\"launchPipelineReexecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)[\n            \"pipelineRunLogs\"\n        ][\"messages\"]\n        assert step_did_not_run(logs, \"spawn\")\n        assert step_did_succeed(logs, \"fail\")\n        assert step_did_fail(logs, \"fail_2\")\n        assert step_did_not_run(logs, \"fail_3\")\n        assert step_did_not_run(logs, \"reset\")\n        assert step_did_not_run(logs, \"collect\")\n\n        retry_two = execute_dagster_graphql_and_finish_runs(\n            graphql_context,\n            LAUNCH_PIPELINE_REEXECUTION_MUTATION,\n            variables={\n                \"executionParams\": {\n                    \"selector\": selector,\n                    \"runConfigData\": retry_config(2),\n                    \"executionMetadata\": {\n                        \"rootRunId\": run_id,\n                        \"parentRunId\": run_id,\n                        \"tags\": [{\"key\": RESUME_RETRY_TAG, \"value\": \"true\"}],\n                    },\n                }\n            },\n        )\n\n        run_id = retry_two.data[\"launchPipelineReexecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)[\n            \"pipelineRunLogs\"\n        ][\"messages\"]\n\n        assert step_did_not_run(logs, \"spawn\")\n        assert step_did_not_run(logs, \"fail\")\n        assert step_did_succeed(logs, \"fail_2\")\n        assert step_did_fail(logs, \"fail_3\")\n        assert step_did_not_run(logs, \"reset\")\n        assert step_did_not_run(logs, \"collect\")\n\n        retry_three = execute_dagster_graphql_and_finish_runs(\n            graphql_context,\n            LAUNCH_PIPELINE_REEXECUTION_MUTATION,\n            variables={\n                \"executionParams\": {\n                    \"selector\": selector,\n                    \"runConfigData\": retry_config(3),\n                    \"executionMetadata\": {\n                        \"rootRunId\": run_id,\n                        \"parentRunId\": run_id,\n                        \"tags\": [{\"key\": RESUME_RETRY_TAG, \"value\": \"true\"}],\n                    },\n                }\n            },\n        )\n\n        run_id = retry_three.data[\"launchPipelineReexecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)[\n            \"pipelineRunLogs\"\n        ][\"messages\"]\n\n        assert step_did_not_run(logs, \"spawn\")\n        assert step_did_not_run(logs, \"fail\")\n        assert step_did_not_run(logs, \"fail_2\")\n        assert step_did_succeed(logs, \"fail_3\")\n        assert step_did_succeed(logs, \"reset\")\n        assert step_did_succeed(logs, \"collect\")\n"
    },
    {
      "id": "dagster-io_dagster_5585_7",
      "input_code": "    def test_retry_multi_output(self, graphql_context: WorkspaceRequestContext):\n        context = graphql_context\n        result = execute_dagster_graphql_and_finish_runs(\n            context,\n            LAUNCH_PIPELINE_EXECUTION_MUTATION,\n            variables={\n                \"executionParams\": get_retry_multi_execution_params(context, should_fail=True)\n            },\n        )\n\n        run_id = result.data[\"launchPipelineExecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(context, run_id)[\"pipelineRunLogs\"][\n            \"messages\"\n        ]\n        assert step_did_succeed(logs, \"multi\")\n        assert step_did_skip(logs, \"child_multi_skip\")\n        assert step_did_fail(logs, \"can_fail\")\n        assert step_did_not_run(logs, \"child_fail\")\n        assert step_did_not_run(logs, \"child_skip\")\n        assert step_did_not_run(logs, \"grandchild_fail\")\n\n        retry_one = execute_dagster_graphql_and_finish_runs(\n            context,\n            LAUNCH_PIPELINE_REEXECUTION_MUTATION,\n            variables={\n                \"executionParams\": get_retry_multi_execution_params(\n                    context, should_fail=True, retry_id=run_id\n                )\n            },\n        )\n\n        run_id = retry_one.data[\"launchPipelineReexecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(context, run_id)[\"pipelineRunLogs\"][\n            \"messages\"\n        ]\n        assert step_did_not_run(logs, \"multi\")\n        assert step_did_not_run(logs, \"child_multi_skip\")\n        assert step_did_fail(logs, \"can_fail\")\n        assert step_did_not_run(logs, \"child_fail\")\n        assert step_did_not_run(logs, \"child_skip\")\n        assert step_did_not_run(logs, \"grandchild_fail\")\n\n        retry_two = execute_dagster_graphql_and_finish_runs(\n            context,\n            LAUNCH_PIPELINE_REEXECUTION_MUTATION,\n            variables={\n                \"executionParams\": get_retry_multi_execution_params(\n                    context, should_fail=False, retry_id=run_id\n                )\n            },\n        )\n\n        run_id = retry_two.data[\"launchPipelineReexecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(context, run_id)[\"pipelineRunLogs\"][\n            \"messages\"\n        ]\n        assert step_did_not_run(logs, \"multi\")\n        assert step_did_not_run(logs, \"child_multi_skip\")\n        assert step_did_succeed(logs, \"can_fail\")\n        assert step_did_succeed(logs, \"child_fail\")\n        assert step_did_skip(logs, \"child_skip\")\n        assert step_did_succeed(logs, \"grandchild_fail\")\n"
    },
    {
      "id": "dagster-io_dagster_5585_4",
      "input_code": "    def test_nested_graph_op_selection_and_config_with_non_null_asset_and_check_selection(\n        self, graphql_context: WorkspaceRequestContext\n    ):\n        selector = infer_job_selector(\n            graphql_context,\n            \"nested_job\",\n            [\"subgraph.adder\", \"subgraph.op_1\"],\n            asset_selection=[],\n            asset_check_selection=[],\n        )\n        run_config = {\"ops\": {\"subgraph\": {\"ops\": {\"adder\": {\"inputs\": {\"num2\": 20}}}}}}\n        result = sync_execute_get_run_log_data(\n            context=graphql_context,\n            variables={\n                \"executionParams\": {\n                    \"selector\": selector,\n                    \"runConfigData\": run_config,\n                }\n            },\n        )\n        logs = result[\"messages\"]\n        assert isinstance(logs, list)\n        assert step_did_succeed(logs, \"subgraph.adder\")\n        assert step_did_succeed(logs, \"subgraph.op_1\")\n        assert step_did_not_run(logs, \"plus_one\")\n        assert step_did_not_run(logs, \"subgraph.op_2\")\n"
    },
    {
      "id": "dagster-io_dagster_5585_10",
      "input_code": "    def test_retry_failure_with_reexecution_params(self, graphql_context: WorkspaceRequestContext):\n        \n        selector = infer_job_selector(graphql_context, \"chained_failure_job\")\n\n        output_file = os.path.join(\n            get_system_temp_directory(), \"chained_failure_job_conditionally_fail\"\n        )\n        try:\n            with open(output_file, \"w\", encoding=\"utf8\"):\n                result = execute_dagster_graphql_and_finish_runs(\n                    graphql_context,\n                    LAUNCH_PIPELINE_EXECUTION_MUTATION,\n                    variables={\n                        \"executionParams\": {\n                            \"selector\": selector,\n                        }\n                    },\n                )\n        finally:\n            os.remove(output_file)\n\n        run_id = result.data[\"launchPipelineExecution\"][\"run\"][\"runId\"]\n        run = graphql_context.instance.get_run_by_id(run_id)\n        assert run and run.status == DagsterRunStatus.FAILURE\n\n        retry = execute_dagster_graphql_and_finish_runs(\n            graphql_context,\n            LAUNCH_PIPELINE_REEXECUTION_MUTATION,\n            variables={\"reexecutionParams\": {\"parentRunId\": run_id, \"strategy\": \"FROM_FAILURE\"}},\n        )\n\n        run_id = retry.data[\"launchPipelineReexecution\"][\"run\"][\"runId\"]\n        run = graphql_context.instance.get_run_by_id(run_id)\n        assert run and run.status == DagsterRunStatus.SUCCESS\n        logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)[\n            \"pipelineRunLogs\"\n        ][\"messages\"]\n        assert step_did_not_run(logs, \"always_succeed\")\n        assert step_did_succeed(logs, \"conditionally_fail\")\n        assert step_did_succeed(logs, \"after_failure\")\n"
    },
    {
      "id": "dagster-io_dagster_5585_11",
      "input_code": "def _do_retry_intermediates_test(graphql_context):\n    selector = infer_job_selector(graphql_context, \"eventually_successful\")\n    result = execute_dagster_graphql_and_finish_runs(\n        graphql_context,\n        LAUNCH_PIPELINE_EXECUTION_MUTATION,\n        variables={\n            \"executionParams\": {\n                \"selector\": selector,\n            }\n        },\n    )\n    assert result.data[\"launchPipelineExecution\"][\"__typename\"] == \"LaunchRunSuccess\"\n    run_id = result.data[\"launchPipelineExecution\"][\"run\"][\"runId\"]\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)[\n        \"pipelineRunLogs\"\n    ][\"messages\"]\n\n    assert step_did_succeed(logs, \"spawn\")\n    assert step_did_fail(logs, \"fail\")\n    assert step_did_not_run(logs, \"fail_2\")\n    assert step_did_not_run(logs, \"fail_3\")\n    assert step_did_not_run(logs, \"reset\")\n\n    retry_one = execute_dagster_graphql_and_finish_runs(\n        graphql_context,\n        LAUNCH_PIPELINE_REEXECUTION_MUTATION,\n        variables={\n            \"executionParams\": {\n                \"selector\": selector,\n                \"executionMetadata\": {\n                    \"rootRunId\": run_id,\n                    \"parentRunId\": run_id,\n                    \"tags\": [{\"key\": RESUME_RETRY_TAG, \"value\": \"true\"}],\n                },\n            }\n        },\n    )\n\n    retry_run_id = retry_one.data[\"launchPipelineReexecution\"][\"run\"][\"runId\"]\n    return retry_run_id\n"
    },
    {
      "id": "dagster-io_dagster_5585_9",
      "input_code": "    def test_retry_asset_job_with_reexecution_params(\n        self, graphql_context: WorkspaceRequestContext\n    ):\n        selector = infer_job_selector(\n            graphql_context, \"two_assets_job\", asset_selection=[{\"path\": [\"asset_one\"]}]\n        )\n        result = execute_dagster_graphql_and_finish_runs(\n            graphql_context,\n            LAUNCH_PIPELINE_EXECUTION_MUTATION,\n            variables={\n                \"executionParams\": {\n                    \"selector\": selector,\n                }\n            },\n        )\n\n        run_id = result.data[\"launchPipelineExecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)[\n            \"pipelineRunLogs\"\n        ][\"messages\"]\n\n        assert step_did_succeed(logs, \"asset_one\")\n        assert step_did_not_run(logs, \"asset_two\")\n\n        retry_one = execute_dagster_graphql_and_finish_runs(\n            graphql_context,\n            LAUNCH_PIPELINE_REEXECUTION_MUTATION,\n            variables={\"reexecutionParams\": {\"parentRunId\": run_id, \"strategy\": \"ALL_STEPS\"}},\n        )\n        run_id = retry_one.data[\"launchPipelineReexecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)[\n            \"pipelineRunLogs\"\n        ][\"messages\"]\n        assert step_did_succeed(logs, \"asset_one\")\n        assert step_did_not_run(logs, \"asset_two\")\n"
    },
    {
      "id": "dagster-io_dagster_5585_3",
      "input_code": "    def test_nested_graph_op_selection_and_config(self, graphql_context: WorkspaceRequestContext):\n        selector = infer_job_selector(\n            graphql_context, \"nested_job\", [\"subgraph.adder\", \"subgraph.op_1\"]\n        )\n        run_config = {\"ops\": {\"subgraph\": {\"ops\": {\"adder\": {\"inputs\": {\"num2\": 20}}}}}}\n        result = sync_execute_get_run_log_data(\n            context=graphql_context,\n            variables={\n                \"executionParams\": {\n                    \"selector\": selector,\n                    \"runConfigData\": run_config,\n                }\n            },\n        )\n        logs = result[\"messages\"]\n        assert isinstance(logs, list)\n        assert step_did_succeed(logs, \"subgraph.adder\")\n        assert step_did_succeed(logs, \"subgraph.op_1\")\n        assert step_did_not_run(logs, \"plus_one\")\n        assert step_did_not_run(logs, \"subgraph.op_2\")\n"
    },
    {
      "id": "dagster-io_dagster_5585_8",
      "input_code": "    def test_retry_hard_failure(self, graphql_context: WorkspaceRequestContext):\n        selector = infer_job_selector(graphql_context, \"hard_failer\")\n        result = execute_dagster_graphql_and_finish_runs(\n            graphql_context,\n            LAUNCH_PIPELINE_EXECUTION_MUTATION,\n            variables={\n                \"executionParams\": {\n                    \"selector\": selector,\n                    \"runConfigData\": {\"ops\": {\"hard_fail_or_0\": {\"config\": {\"fail\": True}}}},\n                }\n            },\n        )\n\n        run_id = result.data[\"launchPipelineExecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)[\n            \"pipelineRunLogs\"\n        ][\"messages\"]\n\n        assert step_started(logs, \"hard_fail_or_0\")\n        assert step_did_not_run(logs, \"hard_fail_or_0\")\n        assert step_did_not_run(logs, \"increment\")\n\n        retry = execute_dagster_graphql_and_finish_runs(\n            graphql_context,\n            LAUNCH_PIPELINE_REEXECUTION_MUTATION,\n            variables={\n                \"executionParams\": {\n                    \"selector\": selector,\n                    \"runConfigData\": {\"ops\": {\"hard_fail_or_0\": {\"config\": {\"fail\": False}}}},\n                    \"executionMetadata\": {\n                        \"rootRunId\": run_id,\n                        \"parentRunId\": run_id,\n                        \"tags\": [{\"key\": RESUME_RETRY_TAG, \"value\": \"true\"}],\n                    },\n                }\n            },\n        )\n\n        run_id = retry.data[\"launchPipelineReexecution\"][\"run\"][\"runId\"]\n        logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)[\n            \"pipelineRunLogs\"\n        ][\"messages\"]\n        assert step_did_succeed(logs, \"hard_fail_or_0\")\n        assert step_did_succeed(logs, \"increment\")\n"
    }
  ],
  "generated_inputs": [
    "<needimport>\nimport json\n\n<testcase_1>\nlogs = [\n    {\"stepKey\": \"step_1\", \"__typename\": \"ExecutionStepSuccessEvent\"},\n    {\"stepKey\": \"step_2\", \"__typename\": \"ExecutionStepFailureEvent\"},\n    {\"stepKey\": \"step_3\", \"__typename\": \"ExecutionStepSkippedEvent\"},\n]\nstep_key = \"step_4\"\n\n<testcase_2>\nlogs = [\n    {\"stepKey\": \"step_1\", \"__typename\": \"ExecutionStepSuccessEvent\"},\n    {\"stepKey\": \"step_2\", \"__typename\": \"ExecutionStepFailureEvent\"},\n    {\"stepKey\": \"step_3\", \"__typename\": \"ExecutionStepSkippedEvent\"},\n    {\"stepKey\": \"step_4\", \"__typename\": \"ExecutionStepSuccessEvent\"},\n]\nstep_key = \"step_5\"\n\n<testcase_3>\nlogs = [\n    {\"stepKey\": \"step_1\", \"__typename\": \"ExecutionStepSuccessEvent\"},\n    {\"stepKey\": \"step_2\", \"__typename\": \"ExecutionStepFailureEvent\"},\n    {\"stepKey\": \"step_3\", \"__typename\": \"ExecutionStepSkippedEvent\"},\n    {\"stepKey\": \"step_4\", \"__typename\": \"ExecutionStepSkippedEvent\"},\n]\nstep_key = \"step_4\"\n\n<testcase_4>\nlogs = [\n    {\"stepKey\": \"step_1\", \"__typename\": \"ExecutionStepSuccessEvent\"},\n    {\"stepKey\": \"step_2\", \"__typename\": \"ExecutionStepFailureEvent\"},\n]\nstep_key = \"step_3\"\n\n<testcase_5>\nlogs = [\n    {\"stepKey\": \"step_1\", \"__typename\": \"ExecutionStepSuccessEvent\"},\n    {\"stepKey\": \"step_2\", \"__typename\": \"ExecutionStepFailureEvent\"},\n    {\"stepKey\": \"step_3\", \"__typename\": \"ExecutionStepSkippedEvent\"},\n    {\"stepKey\": \"step_4\", \"__typename\": \"ExecutionStepFailureEvent\"},\n]\nstep_key = \"step_2\""
  ],
  "gpt_output": "<needimport>\nimport json\n\n<testcase_1>\nlogs = [\n    {\"stepKey\": \"step_1\", \"__typename\": \"ExecutionStepSuccessEvent\"},\n    {\"stepKey\": \"step_2\", \"__typename\": \"ExecutionStepFailureEvent\"},\n    {\"stepKey\": \"step_3\", \"__typename\": \"ExecutionStepSkippedEvent\"},\n]\nstep_key = \"step_4\"\n\n<testcase_2>\nlogs = [\n    {\"stepKey\": \"step_1\", \"__typename\": \"ExecutionStepSuccessEvent\"},\n    {\"stepKey\": \"step_2\", \"__typename\": \"ExecutionStepFailureEvent\"},\n    {\"stepKey\": \"step_3\", \"__typename\": \"ExecutionStepSkippedEvent\"},\n    {\"stepKey\": \"step_4\", \"__typename\": \"ExecutionStepSuccessEvent\"},\n]\nstep_key = \"step_5\"\n\n<testcase_3>\nlogs = [\n    {\"stepKey\": \"step_1\", \"__typename\": \"ExecutionStepSuccessEvent\"},\n    {\"stepKey\": \"step_2\", \"__typename\": \"ExecutionStepFailureEvent\"},\n    {\"stepKey\": \"step_3\", \"__typename\": \"ExecutionStepSkippedEvent\"},\n    {\"stepKey\": \"step_4\", \"__typename\": \"ExecutionStepSkippedEvent\"},\n]\nstep_key = \"step_4\"\n\n<testcase_4>\nlogs = [\n    {\"stepKey\": \"step_1\", \"__typename\": \"ExecutionStepSuccessEvent\"},\n    {\"stepKey\": \"step_2\", \"__typename\": \"ExecutionStepFailureEvent\"},\n]\nstep_key = \"step_3\"\n\n<testcase_5>\nlogs = [\n    {\"stepKey\": \"step_1\", \"__typename\": \"ExecutionStepSuccessEvent\"},\n    {\"stepKey\": \"step_2\", \"__typename\": \"ExecutionStepFailureEvent\"},\n    {\"stepKey\": \"step_3\", \"__typename\": \"ExecutionStepSkippedEvent\"},\n    {\"stepKey\": \"step_4\", \"__typename\": \"ExecutionStepFailureEvent\"},\n]\nstep_key = \"step_2\"",
  "needimport": "import json\n\n",
  "test_results": {
    "ans1": true,
    "ans2": true,
    "ans3": false,
    "ans4": true,
    "ans5": false
  }
}