{
  "input_header": "def _check_linear_int4_k(k, groupsize=1, inner_k_tiles=1):",
  "input_docstring": null,
  "output_code": "def _check_linear_int4_k(k, groupsize=1, inner_k_tiles=1):\n    return k % groupsize == 0 and k % (inner_k_tiles * 16) == 0",
  "input_contexts": [
    {
      "id": "fishaudio_fish-speech_291_2",
      "input_code": "    def create_quantized_state_dict(self):\n        cur_state_dict = self.mod.state_dict()\n        for fqn, mod in self.mod.named_modules():\n            if isinstance(mod, torch.nn.Linear):\n                assert not mod.bias\n                out_features = mod.out_features\n                in_features = mod.in_features\n                assert out_features % 8 == 0, \"require out_features % 8 == 0\"\n                print(f\"linear: {fqn}, in={in_features}, out={out_features}\")\n\n                weight = mod.weight.data\n                if not _check_linear_int4_k(\n                    in_features, self.groupsize, self.inner_k_tiles\n                ):\n                    if self.padding:\n                        import torch.nn.functional as F\n\n                        print(\n                            f\"warning: {fqn} is padded to satisfy in_features % 1024 == 0\"\n                        )\n                        padded_in_features = find_multiple(in_features, 1024)\n                        weight = F.pad(\n                            weight, pad=(0, padded_in_features - in_features)\n                        )\n                    else:\n                        print(\n                            f\"warning: {fqn} is skipped, int4 requires that in_features is 32, 64, or is divisible by 1024, \"\n                            + \"and that groupsize and inner_k_tiles*16 evenly divide into it\"\n                        )\n                        continue\n                (\n                    weight_int4pack,\n                    scales_and_zeros,\n                ) = prepare_int4_weight_and_scales_and_zeros(\n                    weight.to(torch.bfloat16).to(\"cuda\"),\n                    self.groupsize,\n                    self.inner_k_tiles,\n                )\n                cur_state_dict[f\"{fqn}.weight\"] = weight_int4pack.to(\"cpu\")\n                cur_state_dict[f\"{fqn}.scales_and_zeros\"] = scales_and_zeros.to(\"cpu\")\n\n        return cur_state_dict\n"
    },
    {
      "id": "fishaudio_fish-speech_291_1",
      "input_code": "def replace_linear_int4(module, groupsize, inner_k_tiles, padding):\n    for name, child in module.named_children():\n        if isinstance(child, nn.Linear):\n            if _check_linear_int4_k(child.in_features, groupsize, inner_k_tiles):\n                setattr(\n                    module,\n                    name,\n                    WeightOnlyInt4Linear(\n                        child.in_features,\n                        child.out_features,\n                        bias=False,\n                        groupsize=groupsize,\n                        inner_k_tiles=inner_k_tiles,\n                        padding=False,\n                    ),\n                )\n            elif padding:\n                setattr(\n                    module,\n                    name,\n                    WeightOnlyInt4Linear(\n                        child.in_features,\n                        child.out_features,\n                        bias=False,\n                        groupsize=groupsize,\n                        inner_k_tiles=inner_k_tiles,\n                        padding=True,\n                    ),\n                )\n        else:\n            replace_linear_int4(child, groupsize, inner_k_tiles, padding)\n"
    }
  ],
  "generated_inputs": [
    "<needimport>\nimport torch\nimport torch.nn as nn\n\n<testcase_1>\nk = 1024\ngroupsize = 8\ninner_k_tiles = 2\n\n<testcase_2>\nk = 2048\ngroupsize = 16\ninner_k_tiles = 4\n\n<testcase_3>\nk = 512\ngroupsize = 4\ninner_k_tiles = 1\n\n<testcase_4>\nk = 4096\ngroupsize = 32\ninner_k_tiles = 8\n\n<testcase_5>\nk = 8192\ngroupsize = 64\ninner_k_tiles = 16"
  ],
  "gpt_output": "<needimport>\nimport torch\nimport torch.nn as nn\n\n<testcase_1>\nk = 1024\ngroupsize = 8\ninner_k_tiles = 2\n\n<testcase_2>\nk = 2048\ngroupsize = 16\ninner_k_tiles = 4\n\n<testcase_3>\nk = 512\ngroupsize = 4\ninner_k_tiles = 1\n\n<testcase_4>\nk = 4096\ngroupsize = 32\ninner_k_tiles = 8\n\n<testcase_5>\nk = 8192\ngroupsize = 64\ninner_k_tiles = 16",
  "needimport": "import torch\nimport torch.nn as nn\n\n",
  "test_results": {
    "ans1": false,
    "ans2": true,
    "ans3": true,
    "ans4": true,
    "ans5": true
  }
}