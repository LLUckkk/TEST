{
  "input_header": "def progress(cls_name, stats):",
  "input_docstring": "Report progress information, return a string.",
  "output_code": "def progress(cls_name, stats):\n    \n    duration = time.time() - stats[\"t0\"]\n    s = \"%20s classifier : \\t\" % cls_name\n    s += \"%(n_train)6d train docs (%(n_train_pos)6d positive) \" % stats\n    s += \"%(n_test)6d test docs (%(n_test_pos)6d positive) \" % test_stats\n    s += \"accuracy: %(accuracy).3f \" % stats\n    s += \"in %.2fs (%5d docs/s)\" % (duration, stats[\"n_train\"] / duration)\n    return s",
  "input_contexts": [
    {
      "id": "scikit-learn_scikit-learn_368_1",
      "input_code": "def stream_reuters_documents(data_path=None):\n    \n\n    DOWNLOAD_URL = (\n        \"http://archive.ics.uci.edu/ml/machine-learning-databases/\"\n        \"reuters21578-mld/reuters21578.tar.gz\"\n    )\n    ARCHIVE_SHA256 = \"3bae43c9b14e387f76a61b6d82bf98a4fb5d3ef99ef7e7075ff2ccbcf59f9d30\"\n    ARCHIVE_FILENAME = \"reuters21578.tar.gz\"\n\n    if data_path is None:\n        data_path = Path(get_data_home()) / \"reuters\"\n    else:\n        data_path = Path(data_path)\n    if not data_path.exists():\n        \"\"\"Download the dataset.\"\"\"\n        print(\"downloading dataset (once and for all) into %s\" % data_path)\n        data_path.mkdir(parents=True, exist_ok=True)\n\n        def progress(blocknum, bs, size):\n            total_sz_mb = \"%.2f MB\" % (size / 1e6)\n            current_sz_mb = \"%.2f MB\" % ((blocknum * bs) / 1e6)\n            if _not_in_sphinx():\n                sys.stdout.write(\"\\rdownloaded %s / %s\" % (current_sz_mb, total_sz_mb))\n\n        archive_path = data_path / ARCHIVE_FILENAME\n\n        urlretrieve(DOWNLOAD_URL, filename=archive_path, reporthook=progress)\n        if _not_in_sphinx():\n            sys.stdout.write(\"\\r\")\n\n        assert sha256(archive_path.read_bytes()).hexdigest() == ARCHIVE_SHA256\n\n        print(\"untarring Reuters dataset...\")\n        with tarfile.open(archive_path, \"r:gz\") as fp:\n            fp.extractall(data_path, filter=\"data\")\n        print(\"done.\")\n\n    parser = ReutersParser()\n    for filename in data_path.glob(\"*.sgm\"):\n        for doc in parser.parse(open(filename, \"rb\")):\n            yield doc\n"
    }
  ],
  "generated_inputs": [
    "```python\n<needimport>\nimport time\n\n<testcase_1>\ncls_name = \"NaiveBayes\"\nstats = {\n    \"t0\": time.time() - 120,\n    \"n_train\": 1000,\n    \"n_train_pos\": 200,\n    \"n_test\": 400,\n    \"n_test_pos\": 80,\n    \"accuracy\": 0.85\n}\n\n<testcase_2>\ncls_name = \"SVM\"\nstats = {\n    \"t0\": time.time() - 300,\n    \"n_train\": 5000,\n    \"n_train_pos\": 1500,\n    \"n_test\": 2000,\n    \"n_test_pos\": 600,\n    \"accuracy\": 0.92\n}\n\n<testcase_3>\ncls_name = \"RandomForest\"\nstats = {\n    \"t0\": time.time() - 45,\n    \"n_train\": 750,\n    \"n_train_pos\": 300,\n    \"n_test\": 250,\n    \"n_test_pos\": 100,\n    \"accuracy\": 0.78\n}\n\n<testcase_4>\ncls_name = \"LogisticRegression\"\nstats = {\n    \"t0\": time.time() - 180,\n    \"n_train\": 2000,\n    \"n_train_pos\": 800,\n    \"n_test\": 800,\n    \"n_test_pos\": 320,\n    \"accuracy\": 0.88\n}\n\n<testcase_5>\ncls_name = \"KNN\"\nstats = {\n    \"t0\": time.time() - 600,\n    \"n_train\": 3000,\n    \"n_train_pos\": 900,\n    \"n_test\": 1000,\n    \"n_test_pos\": 300,\n    \"accuracy\": 0.81\n}\n```"
  ],
  "gpt_output": "```python\n<needimport>\nimport time\n\n<testcase_1>\ncls_name = \"NaiveBayes\"\nstats = {\n    \"t0\": time.time() - 120,\n    \"n_train\": 1000,\n    \"n_train_pos\": 200,\n    \"n_test\": 400,\n    \"n_test_pos\": 80,\n    \"accuracy\": 0.85\n}\n\n<testcase_2>\ncls_name = \"SVM\"\nstats = {\n    \"t0\": time.time() - 300,\n    \"n_train\": 5000,\n    \"n_train_pos\": 1500,\n    \"n_test\": 2000,\n    \"n_test_pos\": 600,\n    \"accuracy\": 0.92\n}\n\n<testcase_3>\ncls_name = \"RandomForest\"\nstats = {\n    \"t0\": time.time() - 45,\n    \"n_train\": 750,\n    \"n_train_pos\": 300,\n    \"n_test\": 250,\n    \"n_test_pos\": 100,\n    \"accuracy\": 0.78\n}\n\n<testcase_4>\ncls_name = \"LogisticRegression\"\nstats = {\n    \"t0\": time.time() - 180,\n    \"n_train\": 2000,\n    \"n_train_pos\": 800,\n    \"n_test\": 800,\n    \"n_test_pos\": 320,\n    \"accuracy\": 0.88\n}\n\n<testcase_5>\ncls_name = \"KNN\"\nstats = {\n    \"t0\": time.time() - 600,\n    \"n_train\": 3000,\n    \"n_train_pos\": 900,\n    \"n_test\": 1000,\n    \"n_test_pos\": 300,\n    \"accuracy\": 0.81\n}\n```",
  "needimport": "import time\n\n",
  "test_results": {
    "ans1": "          NaiveBayes classifier : \t  1000 train docs (   200 positive)    400 test docs (    80 positive) accuracy: 0.850 in 120.00s (    8 docs/s)",
    "ans2": "                 SVM classifier : \t  5000 train docs (  1500 positive)    400 test docs (    80 positive) accuracy: 0.920 in 300.00s (   16 docs/s)",
    "ans3": "        RandomForest classifier : \t   750 train docs (   300 positive)    400 test docs (    80 positive) accuracy: 0.780 in 45.00s (   16 docs/s)",
    "ans4": "  LogisticRegression classifier : \t  2000 train docs (   800 positive)    400 test docs (    80 positive) accuracy: 0.880 in 180.00s (   11 docs/s)",
    "ans5": "                 KNN classifier : \t  3000 train docs (   900 positive)    400 test docs (    80 positive) accuracy: 0.810 in 600.00s (    5 docs/s)"
  }
}