{
  "input_header": "def get_namespace_from_config(provider_config: Dict[str, Any]) -> str:",
  "input_docstring": null,
  "output_code": "def get_namespace_from_config(provider_config: Dict[str, Any]) -> str:\n    context = get_context_from_config(provider_config)\n    return provider_config.get('namespace',\n                               get_kube_config_context_namespace(context))",
  "input_contexts": [
    {
      "id": "skypilot-org_skypilot_2139_3",
      "input_code": "def terminate_instances(\n    cluster_name_on_cloud: str,\n    provider_config: Dict[str, Any],\n    worker_only: bool = False,\n) -> None:\n    \n    namespace = kubernetes_utils.get_namespace_from_config(provider_config)\n    context = kubernetes_utils.get_context_from_config(provider_config)\n    tag_filters = {\n        TAG_RAY_CLUSTER_NAME: cluster_name_on_cloud,\n    }\n    pods = kubernetes_utils.filter_pods(namespace, context, tag_filters, None)\n\n    networking_mode = network_utils.get_networking_mode(\n        provider_config.get('networking_mode'))\n    if networking_mode == kubernetes_enums.KubernetesNetworkingMode.NODEPORT:\n        pod_name = list(pods.keys())[0]\n        try:\n            kubernetes_utils.clean_zombie_ssh_jump_pod(namespace, context,\n                                                       pod_name)\n        except Exception as e:\n            logger.warning('terminate_instances: Error occurred when analyzing '\n                           f'SSH Jump pod: {e}')\n\n    def _is_head(pod) -> bool:\n        return pod.metadata.labels[constants.TAG_RAY_NODE_KIND] == 'head'\n\n    def _terminate_pod_thread(pod_info):\n        pod_name, pod = pod_info\n        if _is_head(pod) and worker_only:\n            return\n        logger.debug(f'Terminating instance {pod_name}: {pod}')\n        _terminate_node(namespace, context, pod_name)\n\n    subprocess_utils.run_in_parallel(_terminate_pod_thread, list(pods.items()),\n                                     _NUM_THREADS)\n"
    },
    {
      "id": "skypilot-org_skypilot_2139_9",
      "input_code": "def _cleanup_ports_for_ingress(\n    cluster_name_on_cloud: str,\n    ports: List[int],\n    provider_config: Dict[str, Any],\n) -> None:\n    for port in ports:\n        service_name = f'{cluster_name_on_cloud}--skypilot-svc--{port}'\n        network_utils.delete_namespaced_service(\n            namespace=provider_config.get('namespace',\n                                          kubernetes_utils.DEFAULT_NAMESPACE),\n            service_name=service_name,\n        )\n\n    ingress_name = f'{cluster_name_on_cloud}-skypilot-ingress'\n    network_utils.delete_namespaced_ingress(\n        namespace=kubernetes_utils.get_namespace_from_config(provider_config),\n        context=kubernetes_utils.get_context_from_config(provider_config),\n        ingress_name=ingress_name,\n    )\n"
    },
    {
      "id": "skypilot-org_skypilot_2139_8",
      "input_code": "def _open_ports_using_ingress(\n    cluster_name_on_cloud: str,\n    ports: List[int],\n    provider_config: Dict[str, Any],\n) -> None:\n    context = kubernetes_utils.get_context_from_config(provider_config)\n    if not network_utils.ingress_controller_exists(context):\n        raise Exception(\n            'Ingress controller not found. '\n            'Install Nginx ingress controller first: '\n            'https://github.com/kubernetes/ingress-nginx/blob/main/docs/deploy/index.md.'        )\n\n    service_details = [\n        (f'{cluster_name_on_cloud}--skypilot-svc--{port}', port,\n         _PATH_PREFIX.format(\n             cluster_name_on_cloud=cluster_name_on_cloud,\n             port=port,\n             namespace=kubernetes_utils.get_kube_config_context_namespace(\n                 context)).rstrip('/').lstrip('/')) for port in ports\n    ]\n\n    content = network_utils.fill_ingress_template(\n        namespace=provider_config.get('namespace', 'default'),\n        service_details=service_details,\n        ingress_name=f'{cluster_name_on_cloud}-skypilot-ingress',\n        selector_key='skypilot-cluster',\n        selector_value=cluster_name_on_cloud,\n    )\n\n    for service_name, service_spec in content['services_spec'].items():\n        kubernetes_utils.merge_custom_metadata(service_spec['metadata'])\n        network_utils.create_or_replace_namespaced_service(\n            namespace=kubernetes_utils.get_namespace_from_config(\n                provider_config),\n            context=kubernetes_utils.get_context_from_config(provider_config),\n            service_name=service_name,\n            service_spec=service_spec,\n        )\n\n    kubernetes_utils.merge_custom_metadata(content['ingress_spec']['metadata'])\n    network_utils.create_or_replace_namespaced_ingress(\n        namespace=kubernetes_utils.get_namespace_from_config(provider_config),\n        context=kubernetes_utils.get_context_from_config(provider_config),\n        ingress_name=f'{cluster_name_on_cloud}-skypilot-ingress',\n        ingress_spec=content['ingress_spec'],\n    )\n"
    },
    {
      "id": "skypilot-org_skypilot_2139_7",
      "input_code": "def _open_ports_using_loadbalancer(\n    cluster_name_on_cloud: str,\n    ports: List[int],\n    provider_config: Dict[str, Any],\n) -> None:\n    service_name = _LOADBALANCER_SERVICE_NAME.format(\n        cluster_name_on_cloud=cluster_name_on_cloud)\n    content = network_utils.fill_loadbalancer_template(\n        namespace=provider_config.get('namespace', 'default'),\n        service_name=service_name,\n        ports=ports,\n        selector_key='skypilot-cluster',\n        selector_value=cluster_name_on_cloud,\n    )\n\n    kubernetes_utils.merge_custom_metadata(content['service_spec']['metadata'])\n\n    network_utils.create_or_replace_namespaced_service(\n        namespace=kubernetes_utils.get_namespace_from_config(provider_config),\n        context=kubernetes_utils.get_context_from_config(provider_config),\n        service_name=service_name,\n        service_spec=content['service_spec'])\n"
    },
    {
      "id": "skypilot-org_skypilot_2139_6",
      "input_code": "def get_command_runners(\n    cluster_info: common.ClusterInfo,\n    **credentials: Dict[str, Any],\n) -> List[command_runner.CommandRunner]:\n    \n    assert cluster_info.provider_config is not None, cluster_info\n    instances = cluster_info.instances\n    namespace = kubernetes_utils.get_namespace_from_config(\n        cluster_info.provider_config)\n    context = kubernetes_utils.get_context_from_config(\n        cluster_info.provider_config)\n    node_list = []\n    if cluster_info.head_instance_id is not None:\n        node_list = [((namespace, context), cluster_info.head_instance_id)]\n    node_list.extend(((namespace, context), pod_name)\n                     for pod_name in instances.keys()\n                     if pod_name != cluster_info.head_instance_id)\n    return command_runner.KubernetesCommandRunner.make_runner_list(\n        node_list=node_list, **credentials)\n"
    },
    {
      "id": "skypilot-org_skypilot_2139_1",
      "input_code": "def bootstrap_instances(\n        region: str, cluster_name: str,\n        config: common.ProvisionConfig) -> common.ProvisionConfig:\n    del region, cluster_name\n    namespace = kubernetes_utils.get_namespace_from_config(\n        config.provider_config)\n    context = kubernetes_utils.get_context_from_config(config.provider_config)\n\n    _configure_services(namespace, context, config.provider_config)\n\n    networking_mode = network_utils.get_networking_mode(\n        config.provider_config.get('networking_mode'))\n    if networking_mode == kubernetes_enums.KubernetesNetworkingMode.NODEPORT:\n        config = _configure_ssh_jump(namespace, context, config)\n\n    requested_service_account = config.node_config['spec']['serviceAccountName']\n    if (requested_service_account ==\n            kubernetes_utils.DEFAULT_SERVICE_ACCOUNT_NAME):\n        _configure_autoscaler_service_account(namespace, context,\n                                              config.provider_config)\n        _configure_autoscaler_role(namespace,\n                                   context,\n                                   config.provider_config,\n                                   role_field='autoscaler_role')\n        _configure_autoscaler_role_binding(\n            namespace,\n            context,\n            config.provider_config,\n            binding_field='autoscaler_role_binding')\n        _configure_autoscaler_cluster_role(namespace, context,\n                                           config.provider_config)\n        _configure_autoscaler_cluster_role_binding(namespace, context,\n                                                   config.provider_config)\n        _configure_skypilot_system_namespace(config.provider_config)\n        if config.provider_config.get('port_mode', 'loadbalancer') == 'ingress':\n            logger.info('Port mode is set to ingress, setting up ingress role '\n                        'and role binding.')\n            try:\n                _configure_autoscaler_role(namespace,\n                                           context,\n                                           config.provider_config,\n                                           role_field='autoscaler_ingress_role')\n                _configure_autoscaler_role_binding(\n                    namespace,\n                    context,\n                    config.provider_config,\n                    binding_field='autoscaler_ingress_role_binding')\n            except kubernetes.api_exception() as e:\n                if e.status == 404:\n                    logger.info(\n                        'Namespace not found - is your nginx ingress installed?'\n                        ' Skipping ingress role and role binding setup.')\n                else:\n                    raise e\n\n    elif requested_service_account != 'default':\n        logger.info(f'Using service account {requested_service_account!r}, '\n                    'skipping role and role binding setup.')\n    if config.provider_config.get('fuse_device_required', False):\n        _configure_fuse_mounting(config.provider_config)\n    return config\n"
    },
    {
      "id": "skypilot-org_skypilot_2139_10",
      "input_code": "def set_autodown_annotations(handle: 'backends.CloudVmRayResourceHandle',\n                             idle_minutes_to_autostop: Optional[int],\n                             down: bool = False) -> None:\n    \n    tags = {\n        provision_constants.TAG_RAY_CLUSTER_NAME: handle.cluster_name_on_cloud,\n    }\n    ray_config = common_utils.read_yaml(handle.cluster_yaml)\n    provider_config = ray_config['provider']\n    namespace = get_namespace_from_config(provider_config)\n    context = get_context_from_config(provider_config)\n    running_pods = filter_pods(namespace, context, tags)\n\n    for _, pod in running_pods.items():\n        if down:\n            idle_minutes_to_autostop_annotation = {\n                IDLE_MINUTES_TO_AUTOSTOP_ANNOTATION_KEY:\n                    str(idle_minutes_to_autostop)\n            }\n            autodown_annotation = {AUTODOWN_ANNOTATION_KEY: 'true'}\n            _add_pod_annotation(pod=pod,\n                                annotation=idle_minutes_to_autostop_annotation,\n                                namespace=namespace,\n                                context=context)\n            _add_pod_annotation(pod=pod,\n                                annotation=autodown_annotation,\n                                namespace=namespace,\n                                context=context)\n\n        elif (idle_minutes_to_autostop is not None and\n              idle_minutes_to_autostop < 0):\n            _remove_pod_annotation(\n                pod=pod,\n                annotation_key=IDLE_MINUTES_TO_AUTOSTOP_ANNOTATION_KEY,\n                namespace=namespace,\n                context=context)\n            _remove_pod_annotation(pod=pod,\n                                   annotation_key=AUTODOWN_ANNOTATION_KEY,\n                                   namespace=namespace,\n                                   context=context)\n"
    },
    {
      "id": "skypilot-org_skypilot_2139_4",
      "input_code": "def get_cluster_info(\n        region: str,\n        cluster_name_on_cloud: str,\n        provider_config: Optional[Dict[str, Any]] = None) -> common.ClusterInfo:\n    del region\n    assert provider_config is not None\n    namespace = kubernetes_utils.get_namespace_from_config(provider_config)\n    context = kubernetes_utils.get_context_from_config(provider_config)\n    tag_filters = {\n        TAG_RAY_CLUSTER_NAME: cluster_name_on_cloud,\n    }\n\n    running_pods = kubernetes_utils.filter_pods(namespace, context, tag_filters,\n                                                ['Running'])\n\n    pods: Dict[str, List[common.InstanceInfo]] = {}\n    head_pod_name = None\n\n    port_forward_mode = kubernetes_enums.KubernetesNetworkingMode.PORTFORWARD\n    network_mode_str = skypilot_config.get_nested(('kubernetes', 'networking'),\n                                                  port_forward_mode.value)\n    network_mode = kubernetes_enums.KubernetesNetworkingMode.from_str(\n        network_mode_str)\n    external_ip = kubernetes_utils.get_external_ip(network_mode, context)\n    port = 22\n    if not provider_config.get('use_internal_ips', False):\n        port = kubernetes_utils.get_head_ssh_port(cluster_name_on_cloud,\n                                                  namespace, context)\n\n    head_pod_name = None\n    cpu_request = None\n    for pod_name, pod in running_pods.items():\n        internal_ip = pod.status.pod_ip\n        pods[pod_name] = [\n            common.InstanceInfo(\n                instance_id=pod_name,\n                internal_ip=internal_ip,\n                external_ip=(None if network_mode == port_forward_mode else\n                             external_ip),\n                ssh_port=port,\n                tags=pod.metadata.labels,\n            )\n        ]\n        if pod.metadata.labels[constants.TAG_RAY_NODE_KIND] == 'head':\n            head_pod_name = pod_name\n            head_spec = pod.spec\n            assert head_spec is not None, pod\n            cpu_request = head_spec.containers[0].resources.requests['cpu']\n\n    assert cpu_request is not None, 'cpu_request should not be None'\n\n    ssh_user = 'sky'\n    get_k8s_ssh_user_cmd = 'echo $(whoami)'\n    assert head_pod_name is not None\n    runner = command_runner.KubernetesCommandRunner(\n        ((namespace, context), head_pod_name))\n    rc, stdout, stderr = runner.run(get_k8s_ssh_user_cmd,\n                                    require_outputs=True,\n                                    separate_stderr=True,\n                                    stream_logs=False)\n    _raise_command_running_error('get ssh user', get_k8s_ssh_user_cmd,\n                                 head_pod_name, rc, stdout + stderr)\n    ssh_user = stdout.strip()\n    logger.debug(\n        f'Using ssh user {ssh_user} for cluster {cluster_name_on_cloud}')\n\n    return common.ClusterInfo(\n        instances=pods,\n        head_instance_id=head_pod_name,\n        ssh_user=ssh_user,\n        custom_ray_options={\n            'object-store-memory': 500000000,\n            'num-cpus': cpu_request,\n        },\n        provider_name='kubernetes',\n        provider_config=provider_config)\n"
    },
    {
      "id": "skypilot-org_skypilot_2139_5",
      "input_code": "def query_instances(\n    cluster_name_on_cloud: str,\n    provider_config: Optional[Dict[str, Any]] = None,\n    non_terminated_only: bool = True\n) -> Dict[str, Optional[status_lib.ClusterStatus]]:\n    status_map = {\n        'Pending': status_lib.ClusterStatus.INIT,\n        'Running': status_lib.ClusterStatus.UP,\n        'Failed': None,\n        'Unknown': None,\n        'Succeeded': None,\n        'Terminating': None,\n    }\n\n    assert provider_config is not None\n    namespace = kubernetes_utils.get_namespace_from_config(provider_config)\n    context = kubernetes_utils.get_context_from_config(provider_config)\n\n    try:\n        pods = kubernetes.core_api(context).list_namespaced_pod(\n            namespace,\n            label_selector=f'skypilot-cluster={cluster_name_on_cloud}',\n            _request_timeout=kubernetes.API_TIMEOUT).items\n    except kubernetes.max_retry_error():\n        with ux_utils.print_exception_no_traceback():\n            ctx = kubernetes_utils.get_current_kube_config_context_name()\n            raise exceptions.ClusterStatusFetchingError(\n                f'Failed to query cluster {cluster_name_on_cloud!r} status. '\n                'Network error - check if the Kubernetes cluster in '\n                f'context {ctx} is up and accessible.') from None\n    except Exception as e:\n        with ux_utils.print_exception_no_traceback():\n            raise exceptions.ClusterStatusFetchingError(\n                f'Failed to query Kubernetes cluster {cluster_name_on_cloud!r} '\n                f'status: {common_utils.format_exception(e)}')\n\n    cluster_status = {}\n    for pod in pods:\n        pod_status = status_map[pod.status.phase]\n        if non_terminated_only and pod_status is None:\n            continue\n        cluster_status[pod.metadata.name] = pod_status\n    return cluster_status\n"
    },
    {
      "id": "skypilot-org_skypilot_2139_2",
      "input_code": "def _create_pods(region: str, cluster_name_on_cloud: str,\n                 config: common.ProvisionConfig) -> common.ProvisionRecord:\n    \n    provider_config = config.provider_config\n    namespace = kubernetes_utils.get_namespace_from_config(provider_config)\n    context = kubernetes_utils.get_context_from_config(provider_config)\n    pod_spec = copy.deepcopy(config.node_config)\n    tags = {\n        TAG_RAY_CLUSTER_NAME: cluster_name_on_cloud,\n    }\n    pod_spec['metadata']['namespace'] = namespace\n    if 'labels' in pod_spec['metadata']:\n        pod_spec['metadata']['labels'].update(tags)\n    else:\n        pod_spec['metadata']['labels'] = tags\n    pod_spec['metadata']['labels'].update(\n        {TAG_SKYPILOT_CLUSTER_NAME: cluster_name_on_cloud})\n\n    terminating_pods = kubernetes_utils.filter_pods(namespace, context, tags,\n                                                    ['Terminating'])\n    start_time = time.time()\n    while (terminating_pods and\n           time.time() - start_time < _TIMEOUT_FOR_POD_TERMINATION):\n        logger.debug(f'run_instances: Found {len(terminating_pods)} '\n                     'terminating pods. Waiting them to finish: '\n                     f'{list(terminating_pods.keys())}')\n        time.sleep(POLL_INTERVAL)\n        terminating_pods = kubernetes_utils.filter_pods(namespace, context,\n                                                        tags, ['Terminating'])\n\n    if terminating_pods:\n        logger.debug(f'run_instances: Found {len(terminating_pods)} '\n                     'terminating pods still in terminating state after '\n                     f'timeout {_TIMEOUT_FOR_POD_TERMINATION}s. '\n                     'Force deleting them.')\n        for pod_name in terminating_pods.keys():\n            kubernetes.core_api(context).delete_namespaced_pod(\n                pod_name,\n                namespace,\n                _request_timeout=config_lib.DELETION_TIMEOUT,\n                grace_period_seconds=0)\n\n    running_pods = kubernetes_utils.filter_pods(namespace, context, tags,\n                                                ['Pending', 'Running'])\n    head_pod_name = _get_head_pod_name(running_pods)\n    logger.debug(f'Found {len(running_pods)} existing pods: '\n                 f'{list(running_pods.keys())}')\n\n    to_start_count = config.count - len(running_pods)\n    if to_start_count < 0:\n        raise RuntimeError(\n            'The number of running+pending pods '\n            f'({config.count - to_start_count}) in cluster '\n            f'\"{cluster_name_on_cloud}\" is greater than the number '\n            f'requested by the user ({config.count}). '\n            'This is likely a resource leak. '\n            'Use \"sky down\" to terminate the cluster.')\n\n    nvidia_runtime_exists = False\n    try:\n        nvidia_runtime_exists = kubernetes_utils.check_nvidia_runtime_class(\n            context)\n    except kubernetes.kubernetes.client.ApiException as e:\n        logger.warning('run_instances: Error occurred while checking for '\n                       f'nvidia RuntimeClass - '\n                       f'{common_utils.format_exception(e)}'\n                       'Continuing without using nvidia RuntimeClass.\\n'\n                       'If you are on a K3s cluster, manually '\n                       'override runtimeClassName in ~/.sky/config.yaml. '\n                       'For more details, refer to https://docs.skypilot.co/en/latest/reference/config.html')\n\n    needs_gpus = False\n    limits = pod_spec['spec']['containers'][0].get('resources',\n                                                   {}).get('limits')\n    if limits is not None:\n        needs_gpus = limits.get(kubernetes_utils.get_gpu_resource_key(), 0) > 0\n\n    if nvidia_runtime_exists and needs_gpus:\n        pod_spec['spec']['runtimeClassName'] = 'nvidia'\n\n    created_pods = {}\n    logger.debug(f'run_instances: calling create_namespaced_pod '\n                 f'(count={to_start_count}).')\n\n    def _create_pod_thread(i: int):\n        pod_spec_copy = copy.deepcopy(pod_spec)\n        if head_pod_name is None and i == 0:\n            pod_spec_copy['metadata']['labels'].update(constants.HEAD_NODE_TAGS)\n            head_selector = head_service_selector(cluster_name_on_cloud)\n            pod_spec_copy['metadata']['labels'].update(head_selector)\n            pod_spec_copy['metadata']['name'] = f'{cluster_name_on_cloud}-head'\n        else:\n            pod_spec_copy['metadata']['labels'].update(\n                constants.WORKER_NODE_TAGS)\n            pod_uuid = str(uuid.uuid4())[:6]\n            pod_name = f'{cluster_name_on_cloud}-{pod_uuid}'\n            pod_spec_copy['metadata']['name'] = f'{pod_name}-worker'\n            pod_spec_copy['spec']['affinity'] = {\n                'podAntiAffinity': {\n                    'preferredDuringSchedulingIgnoredDuringExecution': [{\n                        'weight': 100,\n                        'podAffinityTerm': {\n                            'labelSelector': {\n                                'matchExpressions': [{\n                                    'key': TAG_SKYPILOT_CLUSTER_NAME,\n                                    'operator': 'In',\n                                    'values': [cluster_name_on_cloud]\n                                }]\n                            },\n                            'topologyKey': 'kubernetes.io/hostname'\n                        }\n                    }]\n                }\n            }\n\n        tpu_label = kubernetes_utils.GKELabelFormatter.TPU_LABEL_KEY\n        if tpu_label in config.node_config.get('spec',\n                                               {}).get('nodeSelector', {}):\n            tpu_toleration = {\n                'key': kubernetes_utils.TPU_RESOURCE_KEY,\n                'operator': 'Equal',\n                'value': 'present',\n                'effect': 'NoSchedule'\n            }\n            pod_spec_copy['spec']['tolerations'] = [tpu_toleration]\n\n        return _create_namespaced_pod_with_retries(namespace, pod_spec_copy,\n                                                   context)\n\n    pods = subprocess_utils.run_in_parallel(_create_pod_thread,\n                                            list(range(to_start_count)),\n                                            _NUM_THREADS)\n\n    for pod in pods:\n        created_pods[pod.metadata.name] = pod\n        if head_pod_name is None and pod.metadata.labels.get(\n                constants.TAG_RAY_NODE_KIND) == 'head':\n            head_pod_name = pod.metadata.name\n\n    networking_mode = network_utils.get_networking_mode(\n        config.provider_config.get('networking_mode'))\n    if networking_mode == kubernetes_enums.KubernetesNetworkingMode.NODEPORT:\n        ssh_jump_pod_name = pod_spec['metadata']['labels']['skypilot-ssh-jump']\n        jump_pod = kubernetes.core_api(context).read_namespaced_pod(\n            ssh_jump_pod_name, namespace)\n        pods.append(jump_pod)\n    provision_timeout = provider_config['timeout']\n\n    wait_str = ('indefinitely'\n                if provision_timeout < 0 else f'for {provision_timeout}s')\n    logger.debug(f'run_instances: waiting {wait_str} for pods to schedule and '\n                 f'run: {[pod.metadata.name for pod in pods]}')\n\n    _wait_for_pods_to_schedule(namespace, context, pods, provision_timeout)\n    logger.debug(f'run_instances: waiting for pods to be running (pulling '\n                 f'images): {[pod.metadata.name for pod in pods]}')\n    _wait_for_pods_to_run(namespace, context, pods)\n    logger.debug(f'run_instances: all pods are scheduled and running: '\n                 f'{[pod.metadata.name for pod in pods]}')\n\n    assert head_pod_name is not None, 'head_instance_id should not be None'\n    return common.ProvisionRecord(\n        provider_name='kubernetes',\n        region=region,\n        zone=None,\n        cluster_name=cluster_name_on_cloud,\n        head_instance_id=head_pod_name,\n        resumed_instance_ids=[],\n        created_instance_ids=list(created_pods.keys()),\n    )\n"
    }
  ],
  "generated_inputs": [
    "<needimport>\nimport kubernetes_utils\nfrom typing import Dict, Any\n\n<testcase_1>\nprovider_config: Dict[str, Any] = {\n    'namespace': 'default',\n    'context': 'minikube'\n}\n\n<testcase_2>\nprovider_config: Dict[str, Any] = {\n    'namespace': 'custom-namespace',\n    'context': 'gke_cluster'\n}\n\n<testcase_3>\nprovider_config: Dict[str, Any] = {\n    'context': 'eks_cluster'\n}\n\n<testcase_4>\nprovider_config: Dict[str, Any] = {\n    'namespace': 'prod-namespace',\n    'context': 'aks_cluster'\n}\n\n<testcase_5>\nprovider_config: Dict[str, Any] = {\n    'namespace': 'dev-namespace',\n    'context': 'k3s_cluster'\n}"
  ],
  "gpt_output": "<needimport>\nimport kubernetes_utils\nfrom typing import Dict, Any\n\n<testcase_1>\nprovider_config: Dict[str, Any] = {\n    'namespace': 'default',\n    'context': 'minikube'\n}\n\n<testcase_2>\nprovider_config: Dict[str, Any] = {\n    'namespace': 'custom-namespace',\n    'context': 'gke_cluster'\n}\n\n<testcase_3>\nprovider_config: Dict[str, Any] = {\n    'context': 'eks_cluster'\n}\n\n<testcase_4>\nprovider_config: Dict[str, Any] = {\n    'namespace': 'prod-namespace',\n    'context': 'aks_cluster'\n}\n\n<testcase_5>\nprovider_config: Dict[str, Any] = {\n    'namespace': 'dev-namespace',\n    'context': 'k3s_cluster'\n}",
  "needimport": "import kubernetes_utils\nfrom typing import Dict, Any\n\n",
  "test_results": {
    "ans1": "default",
    "ans2": "custom-namespace",
    "ans3": "eks-namespace",
    "ans4": "prod-namespace",
    "ans5": "dev-namespace"
  }
}